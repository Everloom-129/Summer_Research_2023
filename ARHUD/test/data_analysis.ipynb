{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saget data parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分开处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "实验安排_0194完成\n",
      "实验安排_0382短完成\n",
      "实验安排_0382长完成\n",
      "实验安排_03b8完成\n",
      "实验安排_0bb4完成\n",
      "实验安排_1629完成\n",
      "实验安排_274e中完成\n",
      "实验安排_274e短完成\n",
      "实验安排_274e长完成\n",
      "实验安排_4659完成\n",
      "实验安排_87bd短完成\n",
      "实验安排_87bd长完成\n",
      "实验安排_bd99 完成\n",
      "实验安排_fe0a短全完成\n",
      "实验安排_fe0a长完成\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "import json\n",
    "\n",
    "def read_from_sagat(input_folder):\n",
    "    # 创建一个字典来存储所有数据\n",
    "    data_dict = {}\n",
    "\n",
    "    # 获取当前目录下的所有Excel文件\n",
    "    excel_files = glob.glob(f'{input_folder}/*.xlsx')\n",
    "\n",
    "    # 迭代所有Excel文件\n",
    "    for file in excel_files:\n",
    "        # 获取文件名（不包含扩展名）\n",
    "        file_name = os.path.splitext(os.path.basename(file))[0]\n",
    "        print(file_name)\n",
    "        # 读取当前Excel文件\n",
    "        test_df = pd.read_excel(file)\n",
    "\n",
    "        # 获取标答的正确次数\n",
    "        standard_row = test_df.loc[test_df['你的姓名'] == '标答']\n",
    "        person_total = standard_row['有关人所有问题答对次数'].values[0]\n",
    "        car_total = standard_row['有关车所有问题答对次数'].values[0] \n",
    "        if car_total ==0:\n",
    "            car_total = 1\n",
    "        other_total = standard_row['识别除人和车之外信息的正确次数'].values[0]\n",
    "\n",
    "        # 迭代DataFrame中的每一行\n",
    "        for index, row in test_df.iterrows():\n",
    "            # 如果姓名是'标答'，则跳过该行\n",
    "            if row['你的姓名'] == '标答':\n",
    "                continue\n",
    "            \n",
    "            # 获取姓名和HUD类型\n",
    "            name = row['你的姓名']\n",
    "            hud_type = row['你使用的平视显示器为']\n",
    "\n",
    "            # 如果名字不在字典中，创建一个新条目\n",
    "            if name not in data_dict:\n",
    "                data_dict[name] = {}\n",
    "\n",
    "            # 如果HUD类型不在名字的字典中，创建一个新条目\n",
    "            if hud_type not in data_dict[name]:\n",
    "                data_dict[name][hud_type] = {}\n",
    "            \n",
    "            data_dict[name][hud_type][file_name] = {\n",
    "                'person_correct_times': float(row['有关人所有问题答对次数']),\n",
    "                'car_correct_times': float(row['有关车所有问题答对次数']),\n",
    "                'other_correct_times': float(row['识别除人和车之外信息的正确次数']),\n",
    "                'person_total': float(person_total),\n",
    "                'car_total': float(car_total),\n",
    "                'other_total': float(other_total),\n",
    "            }\n",
    "\n",
    "    # 导出以查看\n",
    "    with open(f'{input_folder}/data_dict.json', 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data_dict, json_file, ensure_ascii=False, indent=4)\n",
    "read_from_sagat('input_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "周儒\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "徐杨丽\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "陈紫甜\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "田锐抒\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "金亚霏\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "高帅\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "刘佳\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "周佳\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "段景辉\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "刘伟\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "王嘉\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "魏瑜均\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "宫宇航\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "黄惠铭\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "何嘉好\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "达吾列提别克\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "郝思嘉\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "张煜婷\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "杜力\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "邓子昊\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "薛嘉涵\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "陈昕冉\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "黄梦怡\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "蒋笑阳\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "姜昕彤\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "王程业\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "徐盛南\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "徐宇凡\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "于紫琪\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "侯建华\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "胡钰婕\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "周禾嘉\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "王子宸\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "朱一铭\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "楼瀚予\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "刘鹤璐\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "汪靖姗\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "__单风险平视显示器\n",
      "吴易轩\n",
      "__不使用平视显示器\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "郭姝含\n",
      "__单风险平视显示器\n",
      "__双风险平视显示器\n",
      "__不使用平视显示器\n",
      "熊文逸\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "纪子欣\n",
      "__单风险平视显示器\n",
      "__不使用平视显示器\n",
      "__双风险平视显示器\n",
      "NaN\n",
      "__NaN\n",
      "候建华\n",
      "__单风险平视显示器\n",
      "熊文逸 \n",
      "__不使用平视显示器\n",
      "吴易轩 \n",
      "__单风险平视显示器\n",
      "侯建华 \n",
      "__双风险平视显示器\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def calculate_avg_ratios(input_filepath, output_filepath):\n",
    "    # 从JSON文件中读取data_dict\n",
    "    with open(input_filepath, 'r', encoding='utf-8') as file:\n",
    "        data_dict = json.load(file)\n",
    "\n",
    "    # 遍历data_dict来计算平均正确率\n",
    "    for name in data_dict:\n",
    "        print(name)\n",
    "        for hud_type in data_dict[name]:\n",
    "            print(f\"__{hud_type}\")\n",
    "   \n",
    "            # 用于存储每个问卷的正确率\n",
    "            ratios = {'person': [], 'car': [], 'other': [], 'all': []}\n",
    "            #===video===#\n",
    "            for src in data_dict[name][hud_type]:\n",
    "                # 初始化变量来存储累计的正确次数和问题总数\n",
    "                total_correct_times = {'person': 0, 'car': 0, 'other': 0, 'all': 0}\n",
    "                total_questions = {'person': 0, 'car': 0, 'other': 0, 'all': 0}\n",
    "\n",
    "                # 累加正确次数和问题总数\n",
    "                for category in ['person', 'car', 'other']:\n",
    "                    total_correct_times[category] = data_dict[name][hud_type][src][f'{category}_correct_times']\n",
    "                    total_questions[category]     = data_dict[name][hud_type][src][f'{category}_total']\n",
    "\n",
    "                    # 计算并存储每个问卷的正确率\n",
    "                    ratios[category].append(data_dict[name][hud_type][src][f'{category}_correct_times'] / data_dict[name][hud_type][src][f'{category}_total'])\n",
    "\n",
    "                # 计算和存储“all”类别的正确次数和问题总数\n",
    "                total_correct_times['all'] = sum(data_dict[name][hud_type][src][f'{category}_correct_times'] for category in ['person', 'car', 'other'])\n",
    "                total_questions['all']     = sum(data_dict[name][hud_type][src][f'{category}_total'] for category in ['person', 'car', 'other'])\n",
    "                \n",
    "                ratios['all'].append(total_correct_times['all'] / total_questions['all'])\n",
    "            #===video===#\n",
    "          \n",
    "            # print(ratios)\n",
    "            # 计算两种类型的平均正确率\n",
    "            avg_ratio1 = {category: round(sum(ratios[category]) / len(ratios[category]),3) for category in ['person', 'car', 'other', 'all']}\n",
    "            # avg_ratio2 = {category: round(total_correct_times[category] / total_questions[category],3) for category in ['person', 'car', 'other', 'all']}\n",
    "\n",
    "            # 将平均正确率存储到新的键中\n",
    "            data_dict[name][hud_type]['avg_ratio1'] = avg_ratio1\n",
    "            # data_dict[name][hud_type]['avg_ratio2'] = avg_ratio2\n",
    "    \n",
    "    # 保存更新后的data_dict\n",
    "    with open(output_filepath, 'w', encoding='utf-8') as json_file:\n",
    "        json.dump(data_dict, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "# 使用函数\n",
    "calculate_avg_ratios('input_2/data_dict.json', 'input_2/test_output.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "map 的方式转到excel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "\n",
    "\n",
    "def dict_map_excel(input_file,input_folder):\n",
    "    with open(input_file, 'r', encoding='utf-8') as file:\n",
    "        segat_dict = json.load(file)\n",
    "    # HUD 类型的映射\n",
    "    hud_mapping = {\n",
    "        '不使用平视显示器': 'no_HUD',\n",
    "        '单风险平视显示器': 'single_HUD',\n",
    "        '双风险平视显示器': 'double_HUD'\n",
    "    }\n",
    "\n",
    "    # 创建一个列表来存储每行数据\n",
    "    data_rows = []\n",
    "\n",
    "    # 遍历data_dict来创建每行数据\n",
    "    for name, hud_data in segat_dict.items():\n",
    "        row_data = {'Name': name}\n",
    "\n",
    "        for hud_type_cn, stats in hud_data.items():\n",
    "            # 使用映射字典获取英文的 HUD 类型\n",
    "            if hud_type_cn == 'NaN':\n",
    "                continue\n",
    "            hud_type = hud_mapping[hud_type_cn] \n",
    "\n",
    "\n",
    "            # 计算并添加各种正确率到行数据\n",
    "            row_data[f'{hud_type}_all_1'] = stats['avg_ratio1']['all']\n",
    "            # row_data[f'{hud_type}_all_2'] = None\n",
    "            row_data[f'{hud_type}_vehicle_1'] = stats['avg_ratio1']['car']\n",
    "            # row_data[f'{hud_type}_vehicle_2'] = stats['avg_ratio1']['\n",
    "            row_data[f'{hud_type}_pedestrian_1'] = stats['avg_ratio1']['person']\n",
    "            # row_data[f'{hud_type}_pedestrian_2'] = stats['avg_ratio1']['\n",
    "            row_data[f'{hud_type}_other_1'] = stats['avg_ratio1']['other']\n",
    "            # row_data[f'{hud_type}_other_2'] =stats['avg_ratio1']['\n",
    "\n",
    "        # 添加行数据到data_rows\n",
    "        data_rows.append(row_data)\n",
    "\n",
    "    # 创建一个DataFrame\n",
    "    df = pd.DataFrame(data_rows)\n",
    "\n",
    "    # 保存DataFrame为Excel文件\n",
    "    df.to_excel(f'sagat_spss/{input_folder}_output.xlsx', index=False)\n",
    "\n",
    "\n",
    "dict_map_excel('input_2/test_output.json',\"input_2\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\# Courses\\## 大四\\SU23\\Summer_Research_2023\\ARHUD\\test\\data_analysis.ipynb Cell 10\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%23%20Courses/%23%23%20%E5%A4%A7%E5%9B%9B/SU23/Summer_Research_2023/ARHUD/test/data_analysis.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m data_dict\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data_dict' is not defined"
     ]
    }
   ],
   "source": [
    "data_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Step 1 & 2: 读取每一个Excel文件\n",
    "# (请替换 'file1.xlsx', 'file2.xlsx', … 'file15.xlsx' 为您的文件名)\n",
    "files = ['file1.xlsx', 'file2.xlsx', ..., 'file15.xlsx']\n",
    "dfs = [pd.read_excel(file) for file in files]\n",
    "\n",
    "# Step 3: 合并所有的数据\n",
    "merged_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Step 4: 进行初步的数据分析\n",
    "# 查看数据的基本信息，包括每列的数据类型\n",
    "merged_df.info()\n",
    "\n",
    "# 查看描述性统计\n",
    "merged_df.describe()\n",
    "\n",
    "# 保存合并后的数据到一个新的Excel文件\n",
    "merged_df.to_excel('merged_data.xlsx', index=False)\n",
    "\n",
    "# 请在此处添加任何其他您想进行的分析\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ece448",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
