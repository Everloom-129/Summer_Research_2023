# 暑研idea: 结合大规模语言模型的智能汽车安全预警

初始目标：在人机共驾场景中利用大规模语言模型实现风险检测与安全预警。

基础： 

- 自动驾驶领域相关算法，
- 计算机视觉
- 多模态等相关算法

## 对暑研的想法和期望

- 兴趣上来看，个人对自动驾驶比较看好，兴趣浓厚希望未来能投身相关事业，因此也想借暑研的机会提前准备知识

- 个人期望是希望做有关LLM + 自动驾驶的研究，然后能在大四上时参与工作发paper

- 自动驾驶最难搞的就是各种稀奇古怪的corner case，而LLM可以做到few shot learning的能力还是很令人惊叹的

  - 相对于传统的多模态算法，LLM可以视作一个极其强大的Language decoder, 在这方面光是使用Prompt engineering即可达到极好的效果，而若与visual decoder 结合，可以考虑类似MODL的设计

  - 需要算法能自行分析新的情况，并且做出 **符合普通人常识**的应对策略

  - 不存在100%完美的驾驶，但可以避免穷举，利用推理去分析新的问题

## 项目认识

首先，试图使用LLM去做 routing 和 security system显然是极其困难的。暑研时间较紧张，能做到的更多是针对现有车机系统的辅助和提升，有点类似提升siri语音助手的智能

而针对“智能汽车安全预警”，可以参考传统模式下的经验，如高德地图：

- 在导航时提示前方路况多发地段
- 根据实时使用高德人群的GPS信息绘制路线热图，辅助判断拥挤程度
- 根据天气状况预计可能的路面情况，做提前提醒
- 根据车祸通报情况，做出预警
- etc

这些情景都是可以预测，非实时的（ 依赖于外部信息，有比较大的delay）。因为推理过程较短，可以类似哈希表一样，储存起来Q&A。用传统if-else 判断就可以做到相对“智能"的语音助手，推理速度也远超过LLM

而LLM的优势显然不在于这种盲目的复现，他的优势在于**推理和一定程度上的感情认知**（参考认知心理学方面对GPT-4的研究，认为达到了青少年的水平）。我个人认为，以GPT-4的知识和情感水平可以超过90%的人类，这是所有传统的AI所不能匹及的。因此，暑研的关键字之一或许是 **”情感理解能力“**，比方说，可以预防司机路怒症，帮助司机处理车祸后的实时建议，等等。这些往往是传统算法所不能处理或者理解的情景。

**LLM的虽然可以常识性的思考，但人们往往需要的不只是常识** --- 这也是为什么往往都普遍认为传统语音助手如 siri，小艺并不智能，他们只是在一昧的重复百科上的东西，而并没有针对当前情景分析，也就是我认为的“多模态”需要做到的：能自行收集大量的input, 并且根据实时情况分析路况，危险因素等。

但这有一个问题： **信息量缺失**，用户不会事无巨细的向AI汇报他们发现的紧急情况，而缺乏信息是没办法推理的。不过，或许可以用prompt 做补充，在推理到一定程度后总结当前的结果

以GPT-4的Performance和OpenAI prompt engineering 课程为例，若希望LLM生成更准确，更科学的答案，除了scaling training set, 还可以引导他一步一步的思考。这一定程度上可以弥补输入信息不足的问题。所以，暑研的第二个关键字是 **自引导推理**，我认为，当我们说"某个AI很聪明"时，我们的意思是他可以猜到言外之意，提前善解人意的生成我们想要但是没有说出的需求

- 例如，Q: "我今天衣服好像穿少了（对同伴说）" AI: "请问是您冷吗，是否需要我将空调温度调高0.5度呢？" 
- （随即在授权下自行控制车辆交互系统）这样稍微复杂一点点的推理链，是要优于传统算法的（毕竟不需要穷举所有可能，工程量会小很多）

当然，以上的应用情景比较粗糙，但是这两个关键字是我认为LLM可以取代传统算法的核心

### [多模态](https://www.zhihu.com/column/c_1145035792891166720)

目前GPT4看report可以处理visual input, 但是目前依旧尚未发布试用，目前的plugins 也多是基于文本输入交互，本质上仍是text based model。

比较常见的思路跟 **项目认识** 部分大致相同：级联不同的模型，用LLM去驱动其他的AI模型，因为LLM具有推理能力，可以更合理的快速设置模型参数及效果

但问题在于，类似AutoGPT的实现方式无法越过所有的“common sense problem”，比方说LLM可能因为依赖库有问题而陷入local optimum, 局部纠结浪费大量算力。 同时，也无法验证LLM推理结果的ground truth。

这里或许可以使用类似双验证的方式，例如将AutoGPT的内容截取发给另外的LLM, 让他判断是否存在比较愚蠢的反复错误，用prompt 给AutoGPT 摆脱原地打转的反馈 （也就是我们平常分析的方式）

这里比较粗糙，但我认为，通过给定的prompt engieering,应该可以实现模拟人类的工程效果，毕竟LLM所操作的东西都还是基于其他APP的，天然存在信息差，需要自引导推理或许可以加强当前模型的能力

值得思的是，能否用类似finetuning的方式，直接微调图像等其他维度输入的效果？考虑到LLM的token 是离散化的，很难做到比较理想的效果，不知道OpenAI究竟如何实现visual GPT的， 难不成是直接训练大量的图像文本数据？（毕竟那些Dataset里包含的文章应该是含有图片的）

- [ ] 调查：OpenAI训练的pipeline, 思考与多模态的关系
- [x] 阅读相关论文

### 传统安全预警的corner case

边缘场景不只是多RL就能解决的，长尾效应导致需要考虑的因素实在太多了，以下是我查找的几类常见case：

1. 极端天气条件：例如，大雾、雪、冰雹、暴风雨等天气条件可能会严重影响传感器的性能，使得自动驾驶车辆难以识别周围环境。

2. 低照度或夜间驾驶：在夜间或低照度条件下，自动驾驶车辆需要能够通过其传感器有效地检测和识别路面上的障碍物。

3. **不规则交通规则**：比如，临时道路工程、警察手势指挥或者交通事故等情况都可能导致交通规则的临时改变。

4. **与行人和非机动车辆的互动**：例如，行人突然冲出人行道，自行车和摩托车驶入车道，或者遇到动物穿越道路。

5. 高速驾驶和复杂的交通环境：例如，在高速公路上，自动驾驶车辆需要处理高速行驶中的车辆更替和合流等问题；在城市环境中，车辆需要处理交通拥堵、复杂的交叉口和大量的行人和骑行者。

6. **道路标记模糊或缺失**：当路面的标记模糊或者缺失时，自动驾驶车辆可能会难以正确识别驾驶轨迹。

7. GPS或其他传感器信号丢失或干扰：例如，在隧道、大楼下或其他导致信号干扰的地方，自动驾驶车辆可能需要依赖其他传感器或预先存储的地图数据来导航。

加粗的部分是我认为LLM可以进一步辅助现有算法做安全预警

## 幻觉问题

LLM虽然具有强大的处理和理解语言的能力，但也存在着误解和错误推理的可能性。这在普通的对话场景中可能只会导致混淆或不准确的回答，但在自动驾驶这样的安全至关重要的环境中，可能会引发严重的安全问题。

- 例如，在需要提示如何切换车道时，错误理解成如何切换音频，导致错过高速出口等
- 或者，幻觉认为前面的应急车道是正确的更优路径，LLM干预导航算法导致车辆冲上错误车道

1. **词汇歧义**：在您的第一个例子中，"切换"这个词在不同的上下文中可能有不同的含义。LLM可能无法完全理解上下文，错误地将"切换车道"理解为"切换音频"。为了解决这个问题，我们可能需要对LLM进行更多的上下文敏感训练，或者使用更准确、无歧义的词汇。
2. **错误的路径推理**：LLM可能误认为应急车道是一个有效的驾驶路径。这可能是因为LLM缺乏对交通规则和驾驶规范的理解，或者在处理多模态数据（如图像、雷达和激光雷达数据）时出现错误。解决这个问题可能需要更强大的多模态数据处理能力，以及更全面的交通规则和驾驶规范训练。
3. **系统交互问题**：在LLM被集成到车机系统进行实际操作时，可能会出现新的问题。例如，LLM可能无法正确理解或执行如"调整仪表盘亮度"或"关闭车窗"等指令。解决这个问题可能需要更好的系统集成，以及对LLM进行更多的特定任务训练。
4. **系统混乱**：LLM的错误操作或误导可能导致车载系统出现混乱，例如频繁无效的切换操作，引起系统资源的浪费。
5. **增加驾驶员压力**：如果驾驶员需要频繁地纠正LLM的错误决策或操作，这可能增加驾驶员的压力和疲劳，甚至影响驾驶员的注意力。
6. **信任度下降**：如果LLM频繁出现幻觉问题，用户可能会对其产生怀疑，导致对自动驾驶系统的信任度下降。
7. **法律责任**：在某些情况下，LLM的错误决策或操作可能引起法律责任问题，例如导致交通事故或违反交通规则。
8. **破坏品牌形象**：频繁的幻觉问题可能破坏车辆制造商的品牌形象，导致销售下滑或客户流失。

如果只是语音助手或许没有太大危害，但是若需要接入车机交互系统，比方说控制仪表盘亮度，控制车窗关闭。 考虑到系统包装了LLM的情况下变得更复杂而不稳定，则可能引起不必要的麻烦



## 模拟训练的环境

训练LLM的效果，需要如Carla等平台做仿真

但是考虑到前文提到的信息量缺失的问题，Carla 的劣势在于他根本没有车内的人机智能交互情景：

只有第三人称视角，不存在车内驾驶视角

这方面我觉得做的比较好的是游戏，如欧洲卡车模拟2，有非常强大的仿真

但与学姐讨论后，我意识到如果用游戏做仿真，有以下问题：

- **数据获取问题**：难以提取具体实验需要的数据，比如要记录的物理量（转向角航向角）

- **交互性问题**：虽然一些游戏提供了人机交互的场景，但这些场景往往是预设的，无法根据训练的需求进行定制。比如，不能模拟特定的交通事件，不能设置特定的车辆状态等。（比如旁车并道，几辆车，在哪儿生成在哪儿并道）

- **自动驾驶算法的接入问题**：地图的可编辑性低，可以内置的自动驾驶的算法不开源

- **模拟精度问题**：游戏环境往往对真实世界的物理规则进行简化。例如，车辆的动力学模型、摩擦力的模型、气候影响等可能不够精确。这可能导致在游戏环境中表现良好的自动驾驶系统在真实世界中不能正常工作。

  

  

  和一般专门做赛车游戏的侧重点不同，欧卡游戏真实性可能更高点，但是可编辑性和数据可记录性会差一些

## 总结

暑研项目如果作为 **开发工具，写代码**的工程思路出发，我认为比较切实有效的工作是做一个可以跟现有车机交互系统接入的超级智能助手：与传统的语音助手安全提醒相结合，取长补短

这是考虑到，LLM的推理速度远低于传统算法，同时对于网络性能要求较高（毕竟不可能在车上配置A100）

而这个助手有两个特质：

- 情感理解能力
- 自引导推理能力

因为幻觉是生成式模型所必然的，我们不能期待LLM可以作为知识百科，就像New Bing结合了网页搜索能力后表现出的强大智能，将GPT作为推理middle box 才是比较可行有效的
