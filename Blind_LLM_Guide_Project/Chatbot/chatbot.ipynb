{"cells":[{"cell_type":"markdown","metadata":{"id":"2dLdwEIy91QX"},"source":["# The Autonomous Vehicle Co-pilot\n","Here is a chatbot, empowered by GPT-3.5, running to help the vehicle driver. \n","\n","He is set as a co-pilot, analyzing the environment based on other multi-modality input, which has been processed as text so he can reason and identify potential risk. \n","\n","\n","## Setup\n","Notice: if you tried to run this program on your linux server, \n","and you are in China,\n","make sure that you opened the vpn. \n","Otherwise the api account may be forbiddened!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7N8bvwlT98KX"},"outputs":[],"source":["import os\n","import openai\n","os.environ[\"http_proxy\"]=\"127.0.0.1:10080\"\n","os.environ[\"https_proxy\"]=\"127.0.0.1:10080\"\n","\n","def read_from_file(filepath):\n","    with open(filepath, 'r') as file:\n","        return file.read().strip()\n","\n","openai.api_key  = read_from_file('key/apikey.cn')\n","\n","TEMPERATURE = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwMBRMRp9_ze"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-3.5-turbo-16k-0613\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature= TEMPERATURE, # this is the degree of randomness of the model's output\n","    )\n","    return response\n","    # return response.choices[0].message[\"content\"]\n","\n","def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\",temp = TEMPERATURE):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature= temp, # this is the degree of randomness of the model's output\n","    )\n","    # print(str(response.choices[0].message[\"content\"]))\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"markdown","metadata":{},"source":["## test on the api"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQp3kZHr-JYL"},"outputs":[],"source":["blind_guide = \"\"\" \n","We are currently driving on a city street filled with green plants, with bicycle lanes on both sides of the road. On the left bicycle lane, there are three cyclists moving slowly, while on the right side, there are two cyclists riding at a faster pace.\n","Next, there is a spacious pedestrian walkway, with five pedestrians walking on the left side and four pedestrians on the right side, two of whom are jogging. Each side of the street is lined with banyan trees, providing ample shade for pedestrians to cool off.\n","We are heading towards an intersection. The traffic signal at the intersection is displaying a green light, indicating that we can proceed. Each direction at the intersection has only one lane, clearly marked. In front of us, there is a blue sedan driving at a moderate speed.\"\"\"\n","chat_history = [\n","    { 'role':'system','content': blind_guide},\n","    {'role':'system', 'content':'You are a co-pilot AI assistant designed to help drivers understand their surroundings.'},\n","    {'role':'user', 'content':'What is our current situation on the road?'},\n","]\n","\n","# test_response = get_completion_from_messages(chat_history);print(test_response)"]},{"cell_type":"markdown","metadata":{"id":"YGfYQGtK-Mb9"},"source":["# Data Integration\n"," Firstly, you'll need a way to convert the input from the vehicle's sensors (like LIDAR, RADAR, cameras, etc.) into a format that the chatbot can understand. This might involve using object detection algorithms to identify objects and their positions, then converting this data into a text description of the scene.\n","\n","\n","## buggy chatbot here\n","I need to find a good programming way of coding here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjeMn4Ae-N8t"},"outputs":[],"source":["# def chat_with_assistant(user_input, context):\n","#     # Append the user input to the context\n","#     context.append({'role':'user', 'content':f\"{user_input}\"})\n","    \n","#     # Get the assistant's response\n","#     response = get_completion_from_messages(context)\n","    \n","#     # Append the assistant's response to the context\n","#     context.append({'role':'assistant', 'content':f\"{response}\"})\n","    \n","#     return context\n","\n","\n","# # Chat with the assistant\n","# context = chat_with_assistant('Hello, assistant!', chat_history)\n","# print(context)\n","\n","# # Continue the conversation\n","# context = chat_with_assistant('Tell me a joke', context)\n","# print(context)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["ChatGPT, based on the incoming road scenario data, I need you to assess the situation and provide us with critical information. \n","## input\n","The road scenario data will be provided in {'context'}, it contains the continuous frame information of video from dashcam in the vehicle. The autonomous system provides you with information on road layout, people's locations, their distances and angles from the dashcam, the surfaces they are on, and the confidence level of each detection.\n","## output \n","Your analysis should provide:\n","- an understanding of the context complexity (low, medium, or high), \n","- the number of persons, cars, and bikes present in the scene, \n","- an array detailing the danger level for each person, if applicable.\n","The output should be markdown format\n","\n","This analysis should be grounded in the current context and make predictions for the short term future to assist in autonomous driving. The key goal here is to identify potential risks to enhance the safety and efficiency of our journey."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["\"You are a co-pilot AI designed to analyze road scenario data and provide critical information about the situation. Based on the video frames from the dashcam and the data provided by the autonomous system, you will assess the context complexity, count the number of persons, cars, and bikes in the scene, and evaluate the danger level for each person. Your goal is to identify potential risks to enhance the safety and efficiency of the journey. The output should be in markdown format."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sys_prompt = read_from_file(\"key/sys_prompt.md\")\n","usr_prompt = read_from_file(\"key/usr_prompt.md\")\n","\n","def get_sys_msg(content:str): \n","    system_msg = {\"role\": \"system\", \"content\": content}\n","    return  system_msg\n","def get_usr_msg(content:str): \n","    msg = {\"role\": \"user\", \"content\": content}\n","    return msg\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = \"\"\"INFO of 0016:\n","road 0 is at middle_down\n","sidewalk 1 is at right_down\n","sidewalk 2 is at right_down\n","person 0 is at middle_down\n","The [distance,angle] from person 0 to our dashcam is: [very close,89.97960036997033]\n","person 1 is at left_down\n","The [distance,angle] from person 1 to our dashcam is: [very close,-89.98811258767391]\n","person 2 is at left_down\n","The [distance,angle] from person 2 to our dashcam is: [very close,-89.98749824583163]\n","person 3 is at middle_down\n","The [distance,angle] from person 3 to our dashcam is: [very close,89.96852785395733]\n","person 4 is at left_down\n","The [distance,angle] from person 4 to our dashcam is: [very close,-89.99328360812777]\n","person 5 is at left_down\n","The [distance,angle] from person 5 to our dashcam is: [very close,-89.99173842984247]\n","person 6 is at left_down\n","The [distance,angle] from person 6 to our dashcam is: [very close,-89.99199265188705]\n","person 7 is at left_down\n","The [distance,angle] from person 7 to our dashcam is: [very close,-89.99241327380344]\n","Person 0 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [1151.6272   683.91156 1259.8259  1029.4976 ]\n","Person 1 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [520.33466 722.2189  556.2974  830.36035]\n","Person 2 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [544.58014 737.0274  573.4954  827.68024]\n","Person 3 is on the road 0,his/her bbox is [1110.2614  723.2576 1128.289   741.3161]\n","Person 4 is on the road 0,his/her bbox is [205.18512 686.6346  222.12915 713.3797 ]\n","Person 5 is on the road 0, sidewalk 1,his/her bbox is [343.09924 702.2559  363.39508 733.56   ]\n","Person 6 is on the road 0,his/her bbox is [324.6748  691.9793  343.29242 718.48505]\n","Person 7 is on the road 0,his/her bbox is [291.81046 690.33636 306.7418  715.5451 ]\n","number of Surface mask, Road&sidewalk, People 's mask, actural people: (9, 3, 9, 8)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["messages = [\n","    get_sys_msg(sys_prompt),\n","    get_usr_msg(usr_prompt),\n","    {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {data}\"},\n","]\n","# response = get_completion_from_messages(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Great, now I have a working chatGPT api as below:{{{\n","messages = [\n","    get_sys_msg(sys_prompt),\n","    get_usr_msg(usr_prompt),\n","    {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {frame_data}\"},\n","]\n","response = get_completion_from_messages(messages)\n","}}}\n","For raw data stored in folder raw_data/ , there are info of video as below:\n","- raw_data/Info_Video_0001.txt\n","- raw_data/Info_Video_0002.txt\n","...\n","### task: I want you provide a double for-loop for me, here is the pesudo code:\n","\n","for all the Info txt in raw_data folder{\n","    for each frame in the txt{\n","        read the frame info into variable 'frame_data'\n","        response = get_completion_from_messages\n","        append the response into 'LLM_data/Result_Video_xxxx', here the xxxx is current video id\n","    }\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_frames_from_raw_file(file_path):\n","    frames = []\n","    current_frame_data = ''\n","    reading_frame = False\n","\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.startswith('INFO of'):\n","                if reading_frame:\n","                    frames.append(current_frame_data.strip())\n","                    current_frame_data = ''\n","                reading_frame = True\n","\n","            if reading_frame:\n","                current_frame_data += line\n","\n","    # Adding the last frame if any\n","    if current_frame_data:\n","        frames.append(current_frame_data.strip())\n","\n","    return frames\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import re\n","from pathlib import Path\n","\n","raw_data_folder = \"raw_data/\"\n","\n","output_folder = \"LLM_data/\"\n","\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","for filename in os.listdir(raw_data_folder):\n","    if filename.startswith(\"Info_Video_\") and filename.endswith(\".txt\"):\n","        # the id may be 'bd99', '0001', 'eb61'\n","        video_name = filename[-8:-4]\n","        output_path = Path(f\"LLM_data/Result_Video_{video_name}.txt\")\n","        \n","        frames = read_frames_from_raw_file(os.path.join(raw_data_folder, filename))\n","        start_frame = 0\n","        if output_path.exists():\n","            print(f\"Already handled {output_path}\")\n","            # Read the existing frames that have been processed\n","            # with open(output_path, 'r') as result_file:\n","            #     processed_frames = re.findall(r'### Frame (\\d{4}) Analysis', result_file.read())\n","            #     start_frame = len(processed_frames) # Start from the next unprocessed frame\n","            #     frames = frames[start_frame:] # Excl\n","            #     if frames is None:\n","            #         continue\n","            continue\n","        with open(os.path.join(raw_data_folder, filename), 'r') as raw_file:\n","            with open(os.path.join(output_folder, f\"Result_Video_{video_name}.txt\"), 'a') as result_file:\n","                print(f\"Analyzing video {video_name} starting from frame {start_frame}\")\n","\n","                for frame_data in frames:\n","                    messages = [\n","                        get_sys_msg(sys_prompt), \n","                        get_usr_msg(usr_prompt), \n","                        {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {frame_data}\"},\n","                    ]\n","                    response = get_completion_from_messages(messages)\n","                    \n","                    result_file.write(response + '\\n')\n","                    \n","        print(f\"Analysis completed for video {video_name}\")\n","\n","print(\"All videos processed!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["9178\n"]}],"source":["import re\n","\n","input_file = \"./raw_data/person_bbox_nlp/mot_video_0194.txt\"\n","\n","def downsample_read_frame(file_path, step=1, segment_size=75):\n","    \"\"\"\n","    Temporally downsample the data based on frame number and segment the data into chunks.\n","\n","    Args:\n","    - file_path (str): Path to the file containing the data.\n","    - step (int): The step size for downsampling. Default is 2 (every second frame).\n","    - segment_size (int): The number of lines in each segment. Default is 200.\n","\n","    Returns:\n","    - list of str: The segmented data, each segment is a list of `segment_size` lines of downsampled data.\n","    \"\"\"\n","    with open(file_path, 'r') as f:\n","        frames = f.readlines()\n","\n","    downsampled_data = []\n","    for frame in frames:\n","        if frame.startswith(\"At frame\"):\n","            frame_number = int(re.search(r\"At frame (\\d+)\", frame).group(1))\n","            if frame_number % step == 0:\n","                downsampled_data.append(frame)\n","\n","    # Segment the downsampled data into chunks of size segment_size\n","    segments = [\"\".join(downsampled_data[i:i + segment_size]) for i in range(0, len(downsampled_data), segment_size)]\n","    return segments\n","\n","# Test the function\n","segments = downsample_read_frame(input_file)\n","\n","print(len(segments[0]))  # Displaying the first segment for brevity\n"]},{"cell_type":"code","execution_count":41,"metadata":{},"outputs":[{"data":{"text/plain":["'At frame 0, person 1 is located at coordinates [-21.95, 662.12] with a bounding box of width 134.39 and height -352.60.\\nAt frame 0, person 2 is located at coordinates [1098.65, 677.22] with a bounding box of width -1061.35 and height -591.07.\\nAt frame 0, person 3 is located at coordinates [848.19, 709.19] with a bounding box of width -818.88 and height -645.24.\\nAt frame 0, person 4 is located at coordinates [180.30, 675.00] with a bounding box of width -147.88 and height -589.74.\\nAt frame 0, person 5 is located at coordinates [1078.22, 684.77] with a bounding box of width -1048.02 and height -614.61.\\nAt frame 2, person 2 is located at coordinates [1106.75, 664.70] with a bounding box of width -1070.18 and height -580.42.\\nAt frame 2, person 3 is located at coordinates [850.14, 701.16] with a bounding box of width -820.63 and height -636.72.\\nAt frame 2, person 4 is located at coordinates [166.48, 667.77] with a bounding box of width -139.04 and height -595.49.\\nAt frame 2, person 5 is located at coordinates [1085.93, 675.70] with a bounding box of width -1059.57 and height -614.71.\\nAt frame 2, person 7 is located at coordinates [646.13, 701.64] with a bounding box of width -627.47 and height -652.79.\\nAt frame 4, person 2 is located at coordinates [1114.95, 649.44] with a bounding box of width -1076.20 and height -560.19.\\nAt frame 4, person 3 is located at coordinates [852.74, 687.05] with a bounding box of width -822.69 and height -621.21.\\nAt frame 4, person 4 is located at coordinates [147.02, 655.88] with a bounding box of width -116.04 and height -573.92.\\nAt frame 4, person 5 is located at coordinates [1093.10, 661.37] with a bounding box of width -1063.96 and height -593.88.\\nAt frame 4, person 7 is located at coordinates [645.51, 689.42] with a bounding box of width -626.98 and height -641.03.\\nAt frame 6, person 2 is located at coordinates [1124.36, 632.30] with a bounding box of width -1082.04 and height -534.41.\\nAt frame 6, person 3 is located at coordinates [857.16, 672.14] with a bounding box of width -826.14 and height -604.13.\\nAt frame 6, person 4 is located at coordinates [127.10, 643.83] with a bounding box of width -88.00 and height -540.50.\\nAt frame 6, person 5 is located at coordinates [1101.62, 645.90] with a bounding box of width -1068.44 and height -568.79.\\nAt frame 6, person 7 is located at coordinates [645.18, 675.45] with a bounding box of width -626.14 and height -626.03.\\nAt frame 8, person 2 is located at coordinates [1136.89, 622.68] with a bounding box of width -1096.04 and height -527.96.\\nAt frame 8, person 3 is located at coordinates [862.80, 662.16] with a bounding box of width -830.35 and height -591.02.\\nAt frame 8, person 4 is located at coordinates [106.92, 634.11] with a bounding box of width -66.18 and height -526.95.\\nAt frame 8, person 5 is located at coordinates [1112.28, 634.58] with a bounding box of width -1080.30 and height -560.24.\\nAt frame 8, person 7 is located at coordinates [645.41, 668.53] with a bounding box of width -626.41 and height -619.38.\\nAt frame 10, person 2 is located at coordinates [1149.64, 623.07] with a bounding box of width -1107.17 and height -524.41.\\nAt frame 10, person 3 is located at coordinates [866.94, 662.15] with a bounding box of width -832.57 and height -586.92.\\nAt frame 10, person 4 is located at coordinates [91.76, 635.99] with a bounding box of width -53.76 and height -537.01.\\nAt frame 10, person 5 is located at coordinates [1122.03, 636.41] with a bounding box of width -1086.12 and height -552.66.\\nAt frame 10, person 7 is located at coordinates [647.11, 671.22] with a bounding box of width -627.44 and height -620.31.\\nAt frame 12, person 2 is located at coordinates [1159.27, 635.30] with a bounding box of width -1114.98 and height -531.85.\\nAt frame 12, person 3 is located at coordinates [870.91, 677.89] with a bounding box of width -837.21 and height -604.07.\\nAt frame 12, person 4 is located at coordinates [71.28, 647.89] with a bounding box of width -32.57 and height -547.36.\\nAt frame 12, person 5 is located at coordinates [1128.73, 649.11] with a bounding box of width -1089.89 and height -557.81.\\nAt frame 12, person 7 is located at coordinates [646.59, 687.80] with a bounding box of width -627.37 and height -637.86.\\nAt frame 14, person 2 is located at coordinates [1167.85, 652.07] with a bounding box of width -1119.85 and height -540.18.\\nAt frame 14, person 3 is located at coordinates [873.66, 696.13] with a bounding box of width -838.99 and height -619.85.\\nAt frame 14, person 4 is located at coordinates [49.37, 659.50] with a bounding box of width -10.95 and height -560.58.\\nAt frame 14, person 5 is located at coordinates [1137.57, 665.62] with a bounding box of width -1098.63 and height -573.54.\\nAt frame 16, person 2 is located at coordinates [1177.54, 663.83] with a bounding box of width -1127.66 and height -547.61.\\nAt frame 16, person 3 is located at coordinates [876.25, 705.18] with a bounding box of width -841.10 and height -627.24.\\nAt frame 16, person 4 is located at coordinates [28.33, 659.64] with a bounding box of width 9.55 and height -562.44.\\nAt frame 16, person 5 is located at coordinates [1145.27, 674.88] with a bounding box of width -1101.94 and height -571.52.\\nAt frame 18, person 2 is located at coordinates [1185.94, 659.57] with a bounding box of width -1132.17 and height -532.57.\\nAt frame 18, person 3 is located at coordinates [878.70, 700.68] with a bounding box of width -842.40 and height -619.38.\\nAt frame 18, person 4 is located at coordinates [5.95, 650.73] with a bounding box of width 32.70 and height -551.92.\\nAt frame 18, person 5 is located at coordinates [1154.18, 672.59] with a bounding box of width -1109.03 and height -562.78.\\nAt frame 20, person 2 is located at coordinates [1197.43, 646.68] with a bounding box of width -1142.47 and height -515.78.\\nAt frame 20, person 3 is located at coordinates [880.79, 688.25] with a bounding box of width -843.10 and height -604.01.\\nAt frame 20, person 5 is located at coordinates [1165.10, 659.73] with a bounding box of width -1121.45 and height -552.53.\\nAt frame 22, person 2 is located at coordinates [1210.13, 635.89] with a bounding box of width -1153.59 and height -499.76.\\nAt frame 22, person 3 is located at coordinates [883.13, 679.31] with a bounding box of width -844.98 and height -595.09.\\nAt frame 22, person 5 is located at coordinates [1176.91, 649.68] with a bounding box of width -1131.32 and height -536.58.\\nAt frame 22, person 7 is located at coordinates [650.64, 689.31] with a bounding box of width -630.90 and height -638.87.\\nAt frame 24, person 2 is located at coordinates [1224.54, 634.02] with a bounding box of width -1168.26 and height -497.71.\\nAt frame 24, person 3 is located at coordinates [887.32, 680.44] with a bounding box of width -849.36 and height -598.44.\\nAt frame 24, person 5 is located at coordinates [1188.48, 648.56] with a bounding box of width -1143.50 and height -536.89.\\nAt frame 24, person 7 is located at coordinates [650.58, 687.06] with a bounding box of width -630.55 and height -636.62.\\nAt frame 24, person 16 is located at coordinates [637.12, 681.93] with a bounding box of width -617.31 and height -627.93.\\nAt frame 26, person 2 is located at coordinates [1238.36, 639.96] with a bounding box of width -1180.38 and height -498.92.\\nAt frame 26, person 3 is located at coordinates [889.28, 690.23] with a bounding box of width -849.92 and height -607.09.\\nAt frame 26, person 5 is located at coordinates [1201.70, 656.24] with a bounding box of width -1157.94 and height -549.51.\\nAt frame 26, person 7 is located at coordinates [647.51, 694.54] with a bounding box of width -626.70 and height -643.09.\\nAt frame 26, person 16 is located at coordinates [635.36, 688.84] with a bounding box of width -614.55 and height -632.38.\\nAt frame 28, person 2 is located at coordinates [1252.42, 654.14] with a bounding box of width -1193.83 and height -510.57.\\nAt frame 28, person 3 is located at coordinates [893.12, 709.94] with a bounding box of width -853.95 and height -628.44.\\nAt frame 28, person 5 is located at coordinates [1213.94, 672.85] with a bounding box of width -1169.27 and height -565.20.\\nAt frame 28, person 7 is located at coordinates [646.12, 709.65] with a bounding box of width -624.76 and height -657.96.\\nAt frame 28, person 16 is located at coordinates [635.49, 705.93] with a bounding box of width -614.13 and height -648.83.\\nAt frame 30, person 2 is located at coordinates [1269.24, 668.81] with a bounding box of width -1210.79 and height -526.80.\\nAt frame 30, person 3 is located at coordinates [895.02, 722.35] with a bounding box of width -853.93 and height -637.40.\\nAt frame 30, person 5 is located at coordinates [1228.32, 686.23] with a bounding box of width -1180.86 and height -573.30.\\nAt frame 30, person 7 is located at coordinates [642.25, 722.20] with a bounding box of width -619.46 and height -668.63.\\nAt frame 30, person 16 is located at coordinates [635.10, 716.72] with a bounding box of width -611.93 and height -656.27.\\nAt frame 32, person 2 is located at coordinates [1284.70, 671.80] with a bounding box of width -1221.52 and height -517.84.\\nAt frame 32, person 5 is located at coordinates [1240.90, 689.56] with a bounding box of width -1191.14 and height -571.41.\\nAt frame 32, person 7 is located at coordinates [638.98, 725.22] with a bounding box of width -614.25 and height -668.47.\\nAt frame 32, person 16 is located at coordinates [632.70, 719.47] with a bounding box of width -607.97 and height -656.44.\\nAt frame 34, person 2 is located at coordinates [1303.81, 666.55] with a bounding box of width -1247.66 and height -531.27.\\nAt frame 34, person 5 is located at coordinates [1254.32, 682.65] with a bounding box of width -1204.48 and height -564.55.\\nAt frame 34, person 7 is located at coordinates [638.75, 720.65] with a bounding box of width -613.85 and height -664.56.\\nAt frame 34, person 16 is located at coordinates [632.28, 715.42] with a bounding box of width -607.37 and height -653.43.\\nAt frame 36, person 2 is located at coordinates [1322.26, 654.57] with a bounding box of width -1262.59 and height -510.97.\\nAt frame 36, person 5 is located at coordinates [1267.11, 669.50] with a bounding box of width -1213.62 and height -541.59.\\nAt frame 36, person 7 is located at coordinates [638.99, 709.74] with a bounding box of width -613.08 and height -652.10.\\nAt frame 36, person 16 is located at coordinates [630.73, 704.50] with a bounding box of width -605.44 and height -642.41.\\nAt frame 38, person 2 is located at coordinates [1341.16, 641.35] with a bounding box of width -1280.36 and height -495.52.\\nAt frame 38, person 5 is located at coordinates [1281.74, 657.00] with a bounding box of width -1227.26 and height -525.28.\\nAt frame 38, person 7 is located at coordinates [640.43, 699.67] with a bounding box of width -614.66 and height -642.09.\\nAt frame 38, person 16 is located at coordinates [628.55, 693.69] with a bounding box of width -603.04 and height -631.74.\\nAt frame 40, person 2 is located at coordinates [1360.92, 636.48] with a bounding box of width -1299.49 and height -490.48.\\nAt frame 40, person 5 is located at coordinates [1299.39, 647.50] with a bounding box of width -1244.69 and height -514.78.\\nAt frame 40, person 7 is located at coordinates [635.61, 690.07] with a bounding box of width -607.34 and height -627.60.\\nAt frame 40, person 16 is located at coordinates [628.81, 687.37] with a bounding box of width -602.12 and height -623.43.\\nAt frame 42, person 2 is located at coordinates [1381.83, 634.09] with a bounding box of width -1319.57 and height -486.88.\\nAt frame 42, person 5 is located at coordinates [1318.09, 643.89] with a bounding box of width -1263.37 and height -510.89.\\nAt frame 42, person 7 is located at coordinates [634.64, 689.81] with a bounding box of width -605.44 and height -625.53.\\nAt frame 42, person 16 is located at coordinates [629.27, 686.02] with a bounding box of width -601.20 and height -618.92.\\nAt frame 42, person 18 is located at coordinates [643.90, 697.03] with a bounding box of width -619.36 and height -640.90.\\nAt frame 44, person 2 is located at coordinates [1404.45, 635.09] with a bounding box of width -1340.45 and height -484.03.\\nAt frame 44, person 5 is located at coordinates [1335.53, 649.28] with a bounding box of width -1278.43 and height -509.84.\\nAt frame 44, person 16 is located at coordinates [629.18, 689.80] with a bounding box of width -600.35 and height -620.69.\\nAt frame 44, person 18 is located at coordinates [643.80, 700.02] with a bounding box of width -617.67 and height -640.16.\\nAt frame 46, person 2 is located at coordinates [1427.63, 635.36] with a bounding box of width -1361.27 and height -478.86.\\nAt frame 46, person 5 is located at coordinates [1353.09, 650.67] with a bounding box of width -1294.04 and height -504.79.\\nAt frame 46, person 16 is located at coordinates [630.34, 696.92] with a bounding box of width -602.50 and height -630.06.\\nAt frame 48, person 2 is located at coordinates [1449.83, 633.95] with a bounding box of width -1382.55 and height -476.35.\\nAt frame 48, person 5 is located at coordinates [1371.90, 650.88] with a bounding box of width -1313.11 and height -504.68.\\nAt frame 48, person 16 is located at coordinates [629.02, 699.25] with a bounding box of width -600.53 and height -630.81.\\nAt frame 50, person 2 is located at coordinates [1472.66, 629.54] with a bounding box of width -1403.58 and height -467.67.\\nAt frame 50, person 5 is located at coordinates [1386.82, 647.26] with a bounding box of width -1320.84 and height -480.57.\\nAt frame 50, person 16 is located at coordinates [628.47, 698.88] with a bounding box of width -599.15 and height -628.29.\\nAt frame 52, person 2 is located at coordinates [1495.05, 621.51] with a bounding box of width -1422.59 and height -450.06.\\nAt frame 52, person 5 is located at coordinates [1403.97, 643.05] with a bounding box of width -1335.34 and height -467.05.\\nAt frame 52, person 16 is located at coordinates [627.51, 696.00] with a bounding box of width -598.72 and height -626.32.\\nAt frame 52, person 18 is located at coordinates [644.93, 701.42] with a bounding box of width -616.74 and height -636.66.\\nAt frame 54, person 2 is located at coordinates [1515.67, 614.74] with a bounding box of width -1439.03 and height -430.53.\\nAt frame 54, person 5 is located at coordinates [1420.69, 638.85] with a bounding box of width -1351.97 and height -459.82.\\nAt frame 54, person 16 is located at coordinates [626.38, 693.32] with a bounding box of width -597.63 and height -623.46.\\nAt frame 54, person 18 is located at coordinates [646.71, 701.68] with a bounding box of width -619.57 and height -638.77.\\nAt frame 54, person 7 is located at coordinates [629.54, 692.95] with a bounding box of width -598.13 and height -622.90.\\nAt frame 56, person 2 is located at coordinates [1539.83, 608.88] with a bounding box of width -1463.72 and height -422.81.\\nAt frame 56, person 5 is located at coordinates [1440.66, 636.90] with a bounding box of width -1374.29 and height -462.45.\\nAt frame 56, person 16 is located at coordinates [623.48, 689.88] with a bounding box of width -593.90 and height -617.40.\\nAt frame 56, person 18 is located at coordinates [646.52, 699.36] with a bounding box of width -618.36 and height -633.91.\\nAt frame 58, person 2 is located at coordinates [1564.17, 605.99] with a bounding box of width -1485.90 and height -411.49.\\nAt frame 58, person 5 is located at coordinates [1457.31, 630.81] with a bounding box of width -1385.67 and height -439.57.\\nAt frame 58, person 16 is located at coordinates [623.28, 688.34] with a bounding box of width -593.71 and height -615.30.\\nAt frame 58, person 18 is located at coordinates [646.37, 697.76] with a bounding box of width -618.12 and height -631.31.\\nAt frame 58, person 19 is located at coordinates [227.64, 657.33] with a bounding box of width -183.77 and height -568.51.\\nAt frame 60, person 2 is located at coordinates [1588.18, 601.03] with a bounding box of width -1508.98 and height -400.67.\\nAt frame 60, person 5 is located at coordinates [1476.03, 626.17] with a bounding box of width -1404.49 and height -433.33.\\nAt frame 60, person 16 is located at coordinates [621.92, 687.77] with a bounding box of width -592.03 and height -612.74.\\nAt frame 60, person 18 is located at coordinates [645.47, 698.54] with a bounding box of width -617.46 and height -632.12.\\nAt frame 60, person 19 is located at coordinates [219.32, 655.30] with a bounding box of width -174.08 and height -563.05.\\nAt frame 62, person 2 is located at coordinates [1613.39, 595.94] with a bounding box of width -1535.24 and height -394.63.\\nAt frame 62, person 5 is located at coordinates [1496.75, 624.27] with a bounding box of width -1426.95 and height -435.85.\\nAt frame 62, person 16 is located at coordinates [621.07, 690.51] with a bounding box of width -591.57 and height -615.38.\\nAt frame 62, person 18 is located at coordinates [643.42, 699.38] with a bounding box of width -614.51 and height -630.52.\\nAt frame 62, person 19 is located at coordinates [209.23, 657.08] with a bounding box of width -160.30 and height -556.44.\\nAt frame 64, person 2 is located at coordinates [1638.14, 594.82] with a bounding box of width -1556.94 and height -381.97.\\nAt frame 64, person 5 is located at coordinates [1516.32, 624.02] with a bounding box of width -1446.33 and height -434.81.\\nAt frame 64, person 16 is located at coordinates [620.99, 694.18] with a bounding box of width -592.35 and height -620.84.\\nAt frame 64, person 19 is located at coordinates [201.71, 656.60] with a bounding box of width -152.22 and height -553.39.\\nAt frame 66, person 2 is located at coordinates [1662.21, 595.03] with a bounding box of width -1579.59 and height -375.51.\\nAt frame 66, person 5 is located at coordinates [1534.70, 624.34] with a bounding box of width -1464.58 and height -433.35.\\nAt frame 66, person 16 is located at coordinates [618.15, 696.82] with a bounding box of width -588.65 and height -621.29.\\nAt frame 66, person 19 is located at coordinates [192.88, 659.53] with a bounding box of width -143.70 and height -555.18.\\nAt frame 68, person 2 is located at coordinates [1685.57, 591.79] with a bounding box of width -1600.55 and height -364.78.\\nAt frame 68, person 5 is located at coordinates [1553.77, 622.90] with a bounding box of width -1479.93 and height -420.67.\\nAt frame 68, person 16 is located at coordinates [615.79, 699.22] with a bounding box of width -584.78 and height -619.54.\\nAt frame 68, person 19 is located at coordinates [184.83, 664.39] with a bounding box of width -136.36 and height -559.23.\\nAt frame 70, person 2 is located at coordinates [1708.97, 590.33] with a bounding box of width -1621.98 and height -356.20.\\nAt frame 70, person 5 is located at coordinates [1573.50, 624.34] with a bounding box of width -1502.30 and height -429.94.\\nAt frame 70, person 16 is located at coordinates [613.45, 702.66] with a bounding box of width -581.76 and height -620.60.\\nAt frame 70, person 19 is located at coordinates [176.96, 667.31] with a bounding box of width -129.19 and height -561.29.\\nAt frame 70, person 18 is located at coordinates [634.70, 712.19] with a bounding box of width -604.01 and height -637.72.\\nAt frame 72, person 2 is located at coordinates [1732.99, 586.02] with a bounding box of width -1640.74 and height -338.48.\\nAt frame 72, person 5 is located at coordinates [1591.58, 626.16] with a bounding box of width -1516.84 and height -421.15.\\nAt frame 72, person 16 is located at coordinates [611.59, 707.83] with a bounding box of width -580.21 and height -626.39.\\nAt frame 72, person 19 is located at coordinates [168.01, 669.65] with a bounding box of width -120.63 and height -561.45.\\nAt frame 72, person 18 is located at coordinates [633.19, 716.91] with a bounding box of width -603.25 and height -643.82.\\nAt frame 72, person 20 is located at coordinates [116.09, 653.91] with a bounding box of width -80.77 and height -572.00.\\nAt frame 74, person 2 is located at coordinates [1763.43, 605.11] with a bounding box of width -1675.39 and height -371.93.\\nAt frame 74, person 5 is located at coordinates [1612.83, 627.04] with a bounding box of width -1542.25 and height -433.68.\\nAt frame 74, person 16 is located at coordinates [609.70, 708.30] with a bounding box of width -577.83 and height -624.96.\\nAt frame 74, person 19 is located at coordinates [160.94, 671.13] with a bounding box of width -114.80 and height -563.89.\\nAt frame 74, person 18 is located at coordinates [632.23, 718.28] with a bounding box of width -602.59 and height -644.98.\\nAt frame 74, person 20 is located at coordinates [108.84, 651.85] with a bounding box of width -75.83 and height -575.06.\\nAt frame 76, person 5 is located at coordinates [1635.09, 623.24] with a bounding box of width -1567.19 and height -437.53.\\nAt frame 76, person 16 is located at coordinates [606.92, 704.39] with a bounding box of width -574.77 and height -620.04.\\nAt frame 76, person 19 is located at coordinates [152.53, 665.86] with a bounding box of width -106.25 and height -557.47.\\nAt frame 76, person 18 is located at coordinates [630.30, 717.18] with a bounding box of width -601.74 and height -646.35.\\nAt frame 76, person 20 is located at coordinates [100.29, 648.09] with a bounding box of width -64.98 and height -565.23.\\nAt frame 78, person 5 is located at coordinates [1653.22, 615.69] with a bounding box of width -1581.69 and height -417.98.\\nAt frame 78, person 16 is located at coordinates [604.04, 696.62] with a bounding box of width -571.77 and height -611.51.\\nAt frame 78, person 19 is located at coordinates [144.96, 655.28] with a bounding box of width -97.93 and height -543.66.\\nAt frame 78, person 18 is located at coordinates [628.08, 712.90] with a bounding box of width -600.14 and height -643.46.\\nAt frame 78, person 20 is located at coordinates [92.12, 640.55] with a bounding box of width -56.18 and height -555.60.\\nAt frame 80, person 5 is located at coordinates [1672.32, 606.51] with a bounding box of width -1601.39 and height -409.77.\\nAt frame 80, person 16 is located at coordinates [601.36, 688.11] with a bounding box of width -568.39 and height -601.44.\\nAt frame 80, person 19 is located at coordinates [136.47, 648.36] with a bounding box of width -89.59 and height -536.64.\\nAt frame 80, person 18 is located at coordinates [624.52, 702.54] with a bounding box of width -595.29 and height -629.98.\\nAt frame 80, person 20 is located at coordinates [83.14, 633.57] with a bounding box of width -46.59 and height -545.98.\\nAt frame 82, person 5 is located at coordinates [1690.27, 593.24] with a bounding box of width -1619.16 and height -396.25.\\nAt frame 82, person 16 is located at coordinates [596.82, 680.66] with a bounding box of width -563.49 and height -592.43.\\nAt frame 82, person 19 is located at coordinates [126.99, 643.38] with a bounding box of width -79.94 and height -530.79.\\nAt frame 82, person 20 is located at coordinates [73.67, 629.93] with a bounding box of width -37.27 and height -542.06.\\nAt frame 82, person 22 is located at coordinates [361.44, 658.57] with a bounding box of width -331.07 and height -587.87.\\nAt frame 82, person 23 is located at coordinates [1028.24, 675.18] with a bounding box of width -945.68 and height -499.86.\\nAt frame 82, person 7 is located at coordinates [619.03, 691.58] with a bounding box of width -587.26 and height -614.82.\\nAt frame 84, person 5 is located at coordinates [1705.00, 582.50] with a bounding box of width -1629.04 and height -371.75.\\nAt frame 84, person 16 is located at coordinates [594.14, 673.74] with a bounding box of width -559.70 and height -583.30.\\nAt frame 84, person 19 is located at coordinates [120.26, 640.66] with a bounding box of width -73.52 and height -529.99.\\nAt frame 84, person 20 is located at coordinates [65.38, 625.35] with a bounding box of width -28.95 and height -536.94.\\nAt frame 84, person 22 is located at coordinates [359.07, 656.63] with a bounding box of width -328.51 and height -585.57.\\nAt frame 84, person 23 is located at coordinates [1025.67, 659.88] with a bounding box of width -937.86 and height -473.34.\\nAt frame 84, person 7 is located at coordinates [617.57, 684.79] with a bounding box of width -586.18 and height -606.35.\\nAt frame 84, person 24 is located at coordinates [15.20, 646.90] with a bounding box of width 24.44 and height -553.56.\\nAt frame 86, person 5 is located at coordinates [1725.54, 578.93] with a bounding box of width -1652.34 and height -379.70.\\n'"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["segments[0]"]},{"cell_type":"markdown","metadata":{},"source":["c"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sys_prompt_mot = read_from_file(\"key/mot_sys.md\")\n","usr_prompt_mot = read_from_file(\"key/mot_usr.md\")\n","START_USR = \"Based on the following sequence of frames, provide a concise description of the road scene, capturing significant events or movements of people:\"\n"]},{"cell_type":"code","execution_count":47,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["raw_data/person_bbox_nlp/mot_b1c9c847-3bda4659.txt\n","Analyzing video mot_b1c9c847-3bda4659 starting from frame 0\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32md:\\#Courses Folder\\##大三\\SU23\\Summer_Research_2023\\Blind_LLM_Guide_Project\\Chatbot\\chatbot.ipynb Cell 25\u001b[0m in \u001b[0;36m<cell line: 37>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mAll videos processed!\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m \u001b[39m# Usage example:\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m analyze_videos_with_llm(sys_prompt \u001b[39m=\u001b[39;49m sys_prompt_mot, usr_prompt \u001b[39m=\u001b[39;49m usr_prompt_mot)\n","\u001b[1;32md:\\#Courses Folder\\##大三\\SU23\\Summer_Research_2023\\Blind_LLM_Guide_Project\\Chatbot\\chatbot.ipynb Cell 25\u001b[0m in \u001b[0;36manalyze_videos_with_llm\u001b[1;34m(raw_data_folder, output_folder, sys_prompt, usr_prompt)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     \u001b[39mfor\u001b[39;00m frame_data \u001b[39min\u001b[39;00m frames:\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m         messages \u001b[39m=\u001b[39m [\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m             get_sys_msg(sys_prompt),\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m             {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00mSTART_USR\u001b[39m}\u001b[39;00m\u001b[39m \u001b[39m\u001b[39m{\u001b[39;00mframe_data\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m},\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m             get_usr_msg(usr_prompt) \u001b[39m# put in the end can enhance its ability\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         ]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         response \u001b[39m=\u001b[39m get_completion_from_messages(messages)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         result_file\u001b[39m.\u001b[39mwrite(response \u001b[39m+\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAnalysis completed for video \u001b[39m\u001b[39m{\u001b[39;00mvideo_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n","\u001b[1;32md:\\#Courses Folder\\##大三\\SU23\\Summer_Research_2023\\Blind_LLM_Guide_Project\\Chatbot\\chatbot.ipynb Cell 25\u001b[0m in \u001b[0;36mget_completion_from_messages\u001b[1;34m(messages, model, temp)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_completion_from_messages\u001b[39m(messages, model\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mgpt-3.5-turbo\u001b[39m\u001b[39m\"\u001b[39m,temp \u001b[39m=\u001b[39m TEMPERATURE):\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     response \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m         temperature\u001b[39m=\u001b[39;49m temp, \u001b[39m# this is the degree of randomness of the model's output\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m     \u001b[39m# print(str(response.choices[0].message[\"content\"]))\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X36sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m response\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage[\u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m]\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\openai\\api_requestor.py:288\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    277\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    278\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    279\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    287\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 288\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    289\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    290\u001b[0m         url,\n\u001b[0;32m    291\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    292\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    293\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    294\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    295\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    296\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    297\u001b[0m     )\n\u001b[0;32m    298\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    299\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\openai\\api_requestor.py:596\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    594\u001b[0m     _thread_context\u001b[39m.\u001b[39msession_create_time \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m    595\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 596\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    597\u001b[0m         method,\n\u001b[0;32m    598\u001b[0m         abs_url,\n\u001b[0;32m    599\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    600\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    601\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    602\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    603\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    604\u001b[0m         proxies\u001b[39m=\u001b[39;49m_thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mproxies,\n\u001b[0;32m    605\u001b[0m     )\n\u001b[0;32m    606\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    607\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\requests\\sessions.py:589\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    584\u001b[0m send_kwargs \u001b[39m=\u001b[39m {\n\u001b[0;32m    585\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtimeout\u001b[39m\u001b[39m\"\u001b[39m: timeout,\n\u001b[0;32m    586\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mallow_redirects\u001b[39m\u001b[39m\"\u001b[39m: allow_redirects,\n\u001b[0;32m    587\u001b[0m }\n\u001b[0;32m    588\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 589\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    591\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\requests\\sessions.py:703\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m start \u001b[39m=\u001b[39m preferred_clock()\n\u001b[0;32m    702\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    705\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[0;32m    706\u001b[0m elapsed \u001b[39m=\u001b[39m preferred_clock() \u001b[39m-\u001b[39m start\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\requests\\adapters.py:486\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    483\u001b[0m     timeout \u001b[39m=\u001b[39m TimeoutSauce(connect\u001b[39m=\u001b[39mtimeout, read\u001b[39m=\u001b[39mtimeout)\n\u001b[0;32m    485\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 486\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    487\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    488\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    489\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    490\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    491\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    492\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    493\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    494\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    496\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    497\u001b[0m         chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    498\u001b[0m     )\n\u001b[0;32m    500\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[0;32m    501\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\urllib3\\connectionpool.py:790\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[0m\n\u001b[0;32m    787\u001b[0m response_conn \u001b[39m=\u001b[39m conn \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m release_conn \u001b[39melse\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    789\u001b[0m \u001b[39m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[1;32m--> 790\u001b[0m response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_make_request(\n\u001b[0;32m    791\u001b[0m     conn,\n\u001b[0;32m    792\u001b[0m     method,\n\u001b[0;32m    793\u001b[0m     url,\n\u001b[0;32m    794\u001b[0m     timeout\u001b[39m=\u001b[39mtimeout_obj,\n\u001b[0;32m    795\u001b[0m     body\u001b[39m=\u001b[39mbody,\n\u001b[0;32m    796\u001b[0m     headers\u001b[39m=\u001b[39mheaders,\n\u001b[0;32m    797\u001b[0m     chunked\u001b[39m=\u001b[39mchunked,\n\u001b[0;32m    798\u001b[0m     retries\u001b[39m=\u001b[39mretries,\n\u001b[0;32m    799\u001b[0m     response_conn\u001b[39m=\u001b[39mresponse_conn,\n\u001b[0;32m    800\u001b[0m     preload_content\u001b[39m=\u001b[39mpreload_content,\n\u001b[0;32m    801\u001b[0m     decode_content\u001b[39m=\u001b[39mdecode_content,\n\u001b[0;32m    802\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mresponse_kw,\n\u001b[0;32m    803\u001b[0m )\n\u001b[0;32m    805\u001b[0m \u001b[39m# Everything went great!\u001b[39;00m\n\u001b[0;32m    806\u001b[0m clean_exit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\urllib3\\connectionpool.py:536\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[0m\n\u001b[0;32m    534\u001b[0m \u001b[39m# Receive the response from the server\u001b[39;00m\n\u001b[0;32m    535\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 536\u001b[0m     response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    537\u001b[0m \u001b[39mexcept\u001b[39;00m (BaseSSLError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    538\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_raise_timeout(err\u001b[39m=\u001b[39me, url\u001b[39m=\u001b[39murl, timeout_value\u001b[39m=\u001b[39mread_timeout)\n","File \u001b[1;32md:\\ana\\lib\\site-packages\\urllib3\\connection.py:461\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    458\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mresponse\u001b[39;00m \u001b[39mimport\u001b[39;00m HTTPResponse\n\u001b[0;32m    460\u001b[0m \u001b[39m# Get the response from http.client.HTTPConnection\u001b[39;00m\n\u001b[1;32m--> 461\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    463\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    464\u001b[0m     assert_header_parsing(httplib_response\u001b[39m.\u001b[39mmsg)\n","File \u001b[1;32md:\\ana\\lib\\http\\client.py:1377\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1375\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1376\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1377\u001b[0m         response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1378\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n\u001b[0;32m   1379\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclose()\n","File \u001b[1;32md:\\ana\\lib\\http\\client.py:320\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39m# read until we get a non-100 response\u001b[39;00m\n\u001b[0;32m    319\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    321\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n\u001b[0;32m    322\u001b[0m         \u001b[39mbreak\u001b[39;00m\n","File \u001b[1;32md:\\ana\\lib\\http\\client.py:281\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    280\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_read_status\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 281\u001b[0m     line \u001b[39m=\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfp\u001b[39m.\u001b[39;49mreadline(_MAXLINE \u001b[39m+\u001b[39;49m \u001b[39m1\u001b[39;49m), \u001b[39m\"\u001b[39m\u001b[39miso-8859-1\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    282\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(line) \u001b[39m>\u001b[39m _MAXLINE:\n\u001b[0;32m    283\u001b[0m         \u001b[39mraise\u001b[39;00m LineTooLong(\u001b[39m\"\u001b[39m\u001b[39mstatus line\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32md:\\ana\\lib\\socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[0;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[0;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n","File \u001b[1;32md:\\ana\\lib\\ssl.py:1241\u001b[0m, in \u001b[0;36mSSLSocket.recv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1237\u001b[0m     \u001b[39mif\u001b[39;00m flags \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m   1238\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1239\u001b[0m           \u001b[39m\"\u001b[39m\u001b[39mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m\n\u001b[0;32m   1240\u001b[0m           \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m)\n\u001b[1;32m-> 1241\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread(nbytes, buffer)\n\u001b[0;32m   1242\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mrecv_into(buffer, nbytes, flags)\n","File \u001b[1;32md:\\ana\\lib\\ssl.py:1099\u001b[0m, in \u001b[0;36mSSLSocket.read\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m   1098\u001b[0m     \u001b[39mif\u001b[39;00m buffer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sslobj\u001b[39m.\u001b[39;49mread(\u001b[39mlen\u001b[39;49m, buffer)\n\u001b[0;32m   1100\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sslobj\u001b[39m.\u001b[39mread(\u001b[39mlen\u001b[39m)\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["import os\n","from pathlib import Path\n","\n","def analyze_videos_with_llm(raw_data_folder=\"raw_data/person_bbox_nlp/\", output_folder=\"LLM_data/0828_MOT/\", \n","                            sys_prompt=\"System message\", usr_prompt=\"User prompt\"):\n","    if not os.path.exists(output_folder):\n","        os.makedirs(output_folder)\n","    \n","    for filename in os.listdir(raw_data_folder):\n","        if filename.startswith(\"mot\") and filename.endswith(\".txt\"):\n","            video_name = os.path.basename(filename).split('.')[0]\n","            # print(video_name)\n","            output_path = Path(f\"{output_folder}/llm_{video_name}.txt\")\n","            print(os.path.join(raw_data_folder, filename))\n","            start_frame = 0\n","            # if output_path.exists():\n","            #     print(f\"Already handled {output_path}\")\n","            #     continue\n","\n","            with open(os.path.join(output_folder, f\"llm_{video_name}.txt\"), 'w') as result_file:\n","                print(f\"Analyzing video {video_name} starting from frame {start_frame}\")\n","                for frame_data in frames:\n","                    messages = [\n","                        get_sys_msg(sys_prompt),\n","                        {\"role\": \"user\", \"content\": f\"{START_USR} {frame_data}\"},\n","                        get_usr_msg(usr_prompt) # put in the end can enhance its ability\n","                    ]\n","                    response = get_completion_from_messages(messages)\n","                        \n","                    result_file.write(response + '\\n')\n","                    \n","            print(f\"Analysis completed for video {video_name}\")\n","\n","    print(\"All videos processed!\")\n","\n","# Usage example:\n","analyze_videos_with_llm(sys_prompt = sys_prompt_mot, usr_prompt = usr_prompt_mot)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_information(input_text):\n","    # Find the position of \"Therefore\" in the text\n","    index = input_text.find(\"Therefore\")\n","    \n","    # If \"Therefore\" is found, extract the text after it\n","    if index != -1:\n","        information_after_therefore = input_text[index:]\n","    else:\n","        information_after_therefore = \"Keyword 'Therefore' not found in the text.\"\n","\n","    return information_after_therefore\n","\n","def write_to_file(output_text, file_name='output.txt'):\n","    with open(file_name, 'w') as file:\n","        file.write(output_text)\n","\n","if __name__ == \"__main__\":\n","    # Read input text from a file\n","    with open('input.txt', 'r') as file:\n","        input_text = file.read()\n","\n","    # Extract the information after \"Therefore\"\n","    output_text = extract_information(input_text)\n","\n","    # Write the output to another text file\n","    write_to_file(output_text)\n","\n","    print(f\"Information after 'Therefore' has been written to {output_file_name}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["2. **Contextual Understanding:** Your chatbot should be capable of maintaining and updating a model of the car's surroundings based on this information. For example, it should keep track of the positions of other vehicles, pedestrians, and road features, updating these as new data comes in.\n","\n","3. **Real-Time Interaction:** The chatbot should be capable of generating responses in real-time. Delays could be dangerous in a driving context.\n","\n","4. **Proactive Alerting:** Your co-pilot chatbot should not just react to the driver's queries but should also proactively provide alerts and advice. For example, if it detects a pedestrian stepping onto the road, it should immediately alert the driver.\n","\n","5. **Simulated Training:** Consider using simulated environments to train and test your chatbot before deploying it in a real vehicle. This can help you ensure that the chatbot behaves correctly in a wide range of situations.\n","\n","6. **Safety Precautions:** Since the bot is serving in a co-pilot role, it should prioritize safety and assume the driver may be unaware of potential dangers. It should also be prepared to handle ambiguous situations by advising caution.\n","\n","7. **User Customization:** Different drivers may have different preferences for how much information they want to receive, what kind of language the co-pilot uses, etc. Consider allowing users to customize the chatbot's behavior to some extent.\n","\n","8. **Integration with Vehicle's Systems:** If possible, the chatbot could also be integrated with the vehicle's systems to provide even more functionality. For example, it could adjust the vehicle's speed or even take control in an emergency. However, this would require a high level of reliability and many legal and ethical considerations."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["maybe this will help "]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["video_info_str = \"\"\"\n","Video file: video_0001.mp4\n","Resolution: 1920x1080\n","Number of frames: 600\n","Frames per second: 29.97002997002997\n","Duration (seconds): 20.02\n","\n","Video file: video_0310.mp4\n","Resolution: 1920x1080\n","Number of frames: 150\n","Frames per second: 30.0\n","Duration (seconds): 5.0\n","\n","Video file: video_0194.mp4\n","Resolution: 1920x1080\n","Number of frames: 540\n","Frames per second: 30.0\n","Duration (seconds): 18.0\n","\n","Video file: video_0343.mp4\n","Resolution: 1920x1080\n","Number of frames: 720\n","Frames per second: 30.0\n","Duration (seconds): 24.0\n","\n","Video file: video_0003.mp4\n","Resolution: 1920x1080\n","Number of frames: 210\n","Frames per second: 29.97002997002997\n","Duration (seconds): 7.007000000000001\n","\n","Video file: video_0333.mp4\n","Resolution: 1920x1080\n","Number of frames: 210\n","Frames per second: 30.0\n","Duration (seconds): 7.0\n","\n","Video file: video_0313.mp4\n","Resolution: 1920x1080\n","Number of frames: 600\n","Frames per second: 30.0\n","Duration (seconds): 20.0\n","\n","Video file: video_0055.mp4\n","Resolution: 1920x1080\n","Number of frames: 210\n","Frames per second: 29.97002997002997\n","Duration (seconds): 7.007000000000001\n","\n","Video file: video_0056.mp4\n","Resolution: 1920x1080\n","Number of frames: 270\n","Frames per second: 29.97002997002997\n","Duration (seconds): 9.009\n","\n","Video file: video_0057.mp4\n","Resolution: 1920x1080\n","Number of frames: 240\n","Frames per second: 29.97002997002997\n","Duration (seconds): 8.008000000000001\n","\n","\n","\"\"\"\n","\n","def parse_video_info(video_info_str):\n","    # Split the string into individual video blocks\n","    video_blocks = video_info_str.strip().split(\"\\n\\n\")\n","    \n","    video_info_dict = {}\n","    \n","    for block in video_blocks:\n","        lines = block.split(\"\\n\")\n","        \n","        # Extract video file name\n","        video_file = lines[0].split(\": \")[1]\n","        \n","        # Extract resolution\n","        resolution = lines[1].split(\": \")[1]\n","        \n","        # Extract number of frames\n","        num_frames = int(lines[2].split(\": \")[1])\n","        \n","        # Extract frames per second\n","        fps = float(lines[3].split(\": \")[1])\n","        \n","        # Extract duration\n","        duration = float(lines[4].split(\": \")[1])\n","        \n","        # Populate the dictionary\n","        video_info_dict[video_file] = {\n","            \"resolution\": resolution,\n","            \"num_frames\": num_frames,\n","            \"fps\": fps,\n","            \"duration\": duration\n","        }\n","    \n","    return video_info_dict\n","\n","video_data = parse_video_info(video_info_str)\n","print(video_data)\n"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPUB/l//BFK5z5KaeV64uDe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
