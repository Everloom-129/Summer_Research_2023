{"cells":[{"cell_type":"markdown","metadata":{"id":"2dLdwEIy91QX"},"source":["# The Autonomous Vehicle Co-pilot\n","Here is a chatbot, empowered by GPT-3.5, running to help the vehicle driver. \n","\n","He is set as a co-pilot, analyzing the environment based on other multi-modality input, which has been processed as text so he can reason and identify potential risk. \n","\n","\n","## Setup\n","Notice: if you tried to run this program on your linux server, \n","and you are in China,\n","make sure that you opened the vpn. \n","Otherwise the api account may be forbiddened!"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"7N8bvwlT98KX"},"outputs":[],"source":["import os\n","import openai\n","os.environ[\"http_proxy\"]=\"127.0.0.1:21882\"\n","os.environ[\"https_proxy\"]=\"127.0.0.1:21882\"\n","\n","def read_from_file(filepath):\n","    with open(filepath, 'r') as file:\n","        return file.read().strip()\n","\n","openai.api_key  = read_from_file('key/apikey.cn')\n","\n","TEMPERATURE = 0"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"OwMBRMRp9_ze"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-3.5-turbo-16k-0613\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature= TEMPERATURE, # this is the degree of randomness of the model's output\n","    )\n","    return response\n","    # return response.choices[0].message[\"content\"]\n","\n","def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\",temp = TEMPERATURE):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature= temp, # this is the degree of randomness of the model's output\n","    )\n","    print(str(response.choices[0].message[\"content\"]))\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"markdown","metadata":{},"source":["## test on the api"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"xQp3kZHr-JYL"},"outputs":[{"name":"stdout","output_type":"stream","text":["Our current situation on the road is as follows:\n","\n","- We are driving on a city street with green plants and banyan trees lining the sides, providing shade.\n","- There are bicycle lanes on both sides of the road.\n","- On the left bicycle lane, there are three cyclists moving slowly.\n","- On the right bicycle lane, there are two cyclists riding at a faster pace.\n","- Next to the bicycle lanes, there is a spacious pedestrian walkway.\n","- On the left side of the pedestrian walkway, there are five pedestrians walking.\n","- On the right side of the pedestrian walkway, there are four pedestrians, two of whom are jogging.\n","- We are approaching an intersection.\n","- The traffic signal at the intersection is displaying a green light, indicating that we can proceed.\n","- In front of us, there is a blue sedan driving at a moderate speed.\n"]}],"source":["blind_guide = \"\"\" \n","We are currently driving on a city street filled with green plants, with bicycle lanes on both sides of the road. On the left bicycle lane, there are three cyclists moving slowly, while on the right side, there are two cyclists riding at a faster pace.\n","Next, there is a spacious pedestrian walkway, with five pedestrians walking on the left side and four pedestrians on the right side, two of whom are jogging. Each side of the street is lined with banyan trees, providing ample shade for pedestrians to cool off.\n","We are heading towards an intersection. The traffic signal at the intersection is displaying a green light, indicating that we can proceed. Each direction at the intersection has only one lane, clearly marked. In front of us, there is a blue sedan driving at a moderate speed.\"\"\"\n","chat_history = [\n","    { 'role':'system','content': blind_guide},\n","    {'role':'system', 'content':'You are a co-pilot AI assistant designed to help drivers understand their surroundings.'},\n","    {'role':'user', 'content':'What is our current situation on the road?'},\n","]\n","\n","test_reponse = get_completion_from_messages(chat_history)"]},{"cell_type":"markdown","metadata":{"id":"YGfYQGtK-Mb9"},"source":["# Data Integration\n"," Firstly, you'll need a way to convert the input from the vehicle's sensors (like LIDAR, RADAR, cameras, etc.) into a format that the chatbot can understand. This might involve using object detection algorithms to identify objects and their positions, then converting this data into a text description of the scene.\n","\n","\n","## buggy chatbot here\n","I need to find a good programming way of coding here"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"SjeMn4Ae-N8t"},"outputs":[{"name":"stdout","output_type":"stream","text":["Hello! Based on the information provided, our current situation on the road is as follows:\n","\n","- We are driving on a city street with green plants and banyan trees lining the sides.\n","- There are bicycle lanes on both sides of the road.\n","- On the left bicycle lane, there are three cyclists moving slowly.\n","- On the right bicycle lane, there are two cyclists riding at a faster pace.\n","- Next to the bicycle lanes, there is a spacious pedestrian walkway.\n","- On the left side of the pedestrian walkway, there are five pedestrians walking.\n","- On the right side of the pedestrian walkway, there are four pedestrians, two of whom are jogging.\n","- We are approaching an intersection.\n","- The traffic signal at the intersection is displaying a green light, indicating that we can proceed.\n","- In front of us, there is a blue sedan driving at a moderate speed.\n","\n","Is there anything specific you would like to know or any assistance you need?\n","[{'role': 'system', 'content': ' \\nWe are currently driving on a city street filled with green plants, with bicycle lanes on both sides of the road. On the left bicycle lane, there are three cyclists moving slowly, while on the right side, there are two cyclists riding at a faster pace.\\nNext, there is a spacious pedestrian walkway, with five pedestrians walking on the left side and four pedestrians on the right side, two of whom are jogging. Each side of the street is lined with banyan trees, providing ample shade for pedestrians to cool off.\\nWe are heading towards an intersection. The traffic signal at the intersection is displaying a green light, indicating that we can proceed. Each direction at the intersection has only one lane, clearly marked. In front of us, there is a blue sedan driving at a moderate speed.'}, {'role': 'system', 'content': 'You are a co-pilot AI assistant designed to help drivers understand their surroundings.'}, {'role': 'user', 'content': 'What is our current situation on the road?'}, {'role': 'user', 'content': 'Hello, assistant!'}, {'role': 'assistant', 'content': 'Hello! Based on the information provided, our current situation on the road is as follows:\\n\\n- We are driving on a city street with green plants and banyan trees lining the sides.\\n- There are bicycle lanes on both sides of the road.\\n- On the left bicycle lane, there are three cyclists moving slowly.\\n- On the right bicycle lane, there are two cyclists riding at a faster pace.\\n- Next to the bicycle lanes, there is a spacious pedestrian walkway.\\n- On the left side of the pedestrian walkway, there are five pedestrians walking.\\n- On the right side of the pedestrian walkway, there are four pedestrians, two of whom are jogging.\\n- We are approaching an intersection.\\n- The traffic signal at the intersection is displaying a green light, indicating that we can proceed.\\n- In front of us, there is a blue sedan driving at a moderate speed.\\n\\nIs there anything specific you would like to know or any assistance you need?'}]\n","Sure, here's a joke for you:\n","\n","Why don't scientists trust atoms?\n","\n","Because they make up everything!\n","[{'role': 'system', 'content': ' \\nWe are currently driving on a city street filled with green plants, with bicycle lanes on both sides of the road. On the left bicycle lane, there are three cyclists moving slowly, while on the right side, there are two cyclists riding at a faster pace.\\nNext, there is a spacious pedestrian walkway, with five pedestrians walking on the left side and four pedestrians on the right side, two of whom are jogging. Each side of the street is lined with banyan trees, providing ample shade for pedestrians to cool off.\\nWe are heading towards an intersection. The traffic signal at the intersection is displaying a green light, indicating that we can proceed. Each direction at the intersection has only one lane, clearly marked. In front of us, there is a blue sedan driving at a moderate speed.'}, {'role': 'system', 'content': 'You are a co-pilot AI assistant designed to help drivers understand their surroundings.'}, {'role': 'user', 'content': 'What is our current situation on the road?'}, {'role': 'user', 'content': 'Hello, assistant!'}, {'role': 'assistant', 'content': 'Hello! Based on the information provided, our current situation on the road is as follows:\\n\\n- We are driving on a city street with green plants and banyan trees lining the sides.\\n- There are bicycle lanes on both sides of the road.\\n- On the left bicycle lane, there are three cyclists moving slowly.\\n- On the right bicycle lane, there are two cyclists riding at a faster pace.\\n- Next to the bicycle lanes, there is a spacious pedestrian walkway.\\n- On the left side of the pedestrian walkway, there are five pedestrians walking.\\n- On the right side of the pedestrian walkway, there are four pedestrians, two of whom are jogging.\\n- We are approaching an intersection.\\n- The traffic signal at the intersection is displaying a green light, indicating that we can proceed.\\n- In front of us, there is a blue sedan driving at a moderate speed.\\n\\nIs there anything specific you would like to know or any assistance you need?'}, {'role': 'user', 'content': 'Tell me a joke'}, {'role': 'assistant', 'content': \"Sure, here's a joke for you:\\n\\nWhy don't scientists trust atoms?\\n\\nBecause they make up everything!\"}]\n"]}],"source":["# def chat_with_assistant(user_input, context):\n","#     # Append the user input to the context\n","#     context.append({'role':'user', 'content':f\"{user_input}\"})\n","    \n","#     # Get the assistant's response\n","#     response = get_completion_from_messages(context)\n","    \n","#     # Append the assistant's response to the context\n","#     context.append({'role':'assistant', 'content':f\"{response}\"})\n","    \n","#     return context\n","\n","\n","# # Chat with the assistant\n","# context = chat_with_assistant('Hello, assistant!', chat_history)\n","# print(context)\n","\n","# # Continue the conversation\n","# context = chat_with_assistant('Tell me a joke', context)\n","# print(context)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["ChatGPT, based on the incoming road scenario data, I need you to assess the situation and provide us with critical information. \n","## input\n","The road scenario data will be provided in {'context'}, it contains the continuous frame information of video from dashcam in the vehicle. The autonomous system provides you with information on road layout, people's locations, their distances and angles from the dashcam, the surfaces they are on, and the confidence level of each detection.\n","## output \n","Your analysis should provide:\n","- an understanding of the context complexity (low, medium, or high), \n","- the number of persons, cars, and bikes present in the scene, \n","- an array detailing the danger level for each person, if applicable.\n","The output should be markdown format\n","\n","This analysis should be grounded in the current context and make predictions for the short term future to assist in autonomous driving. The key goal here is to identify potential risks to enhance the safety and efficiency of our journey."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["\"You are a co-pilot AI designed to analyze road scenario data and provide critical information about the situation. Based on the video frames from the dashcam and the data provided by the autonomous system, you will assess the context complexity, count the number of persons, cars, and bikes in the scene, and evaluate the danger level for each person. Your goal is to identify potential risks to enhance the safety and efficiency of the journey. The output should be in markdown format."]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["sys_prompt = read_from_file(\"key/sys_prompt.md\")\n","usr_prompt = read_from_file(\"key/usr_prompt.md\")\n","\n","def get_sys_msg(content:str): \n","    system_msg = {\"role\": \"system\", \"content\": content}\n","    return  system_msg\n","def get_usr_msg(content:str): \n","    msg = {\"role\": \"user\", \"content\": content}\n","    return msg\n"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["data = \"\"\"INFO of 0016:\n","road 0 is at middle_down\n","sidewalk 1 is at right_down\n","sidewalk 2 is at right_down\n","person 0 is at middle_down\n","The [distance,angle] from person 0 to our dashcam is: [very close,89.97960036997033]\n","person 1 is at left_down\n","The [distance,angle] from person 1 to our dashcam is: [very close,-89.98811258767391]\n","person 2 is at left_down\n","The [distance,angle] from person 2 to our dashcam is: [very close,-89.98749824583163]\n","person 3 is at middle_down\n","The [distance,angle] from person 3 to our dashcam is: [very close,89.96852785395733]\n","person 4 is at left_down\n","The [distance,angle] from person 4 to our dashcam is: [very close,-89.99328360812777]\n","person 5 is at left_down\n","The [distance,angle] from person 5 to our dashcam is: [very close,-89.99173842984247]\n","person 6 is at left_down\n","The [distance,angle] from person 6 to our dashcam is: [very close,-89.99199265188705]\n","person 7 is at left_down\n","The [distance,angle] from person 7 to our dashcam is: [very close,-89.99241327380344]\n","Person 0 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [1151.6272   683.91156 1259.8259  1029.4976 ]\n","Person 1 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [520.33466 722.2189  556.2974  830.36035]\n","Person 2 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [544.58014 737.0274  573.4954  827.68024]\n","Person 3 is on the road 0,his/her bbox is [1110.2614  723.2576 1128.289   741.3161]\n","Person 4 is on the road 0,his/her bbox is [205.18512 686.6346  222.12915 713.3797 ]\n","Person 5 is on the road 0, sidewalk 1,his/her bbox is [343.09924 702.2559  363.39508 733.56   ]\n","Person 6 is on the road 0,his/her bbox is [324.6748  691.9793  343.29242 718.48505]\n","Person 7 is on the road 0,his/her bbox is [291.81046 690.33636 306.7418  715.5451 ]\n","number of Surface mask, Road&sidewalk, People 's mask, actural people: (9, 3, 9, 8)\"\"\""]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["### Frame 0016 Analysis\n","\n","**Summary of Key Frame Information:**\n","- **Road Position:** The road (road 0) is located in the middle-down region of the frame.\n","- **Sidewalk Positions:** Sidewalk 1 and sidewalk 2 are located in the right-down region of the frame.\n","- **People Positions and Distances:**\n","  - **Person 0:** Located at middle-down, very close to the dashcam, with an angle of 89.98 degrees. On road 0, sidewalk 1, sidewalk 2.\n","  - **Person 1:** Located at left-down, very close to the dashcam, with an angle of -89.99 degrees. On road 0, sidewalk 1, sidewalk 2.\n","  - **Person 2:** Located at left-down, very close to the dashcam, with an angle of -89.99 degrees. On road 0, sidewalk 1, sidewalk 2.\n","  - **Person 3:** Located at middle-down, very close to the dashcam, with an angle of 89.97 degrees. On road 0.\n","  - **Person 4:** Located at left-down, very close to the dashcam, with an angle of -89.99 degrees. On road 0.\n","  - **Person 5:** Located at left-down, very close to the dashcam, with an angle of -89.99 degrees. On road 0, sidewalk 1.\n","  - **Person 6:** Located at left-down, very close to the dashcam, with an angle of -89.99 degrees. On road 0.\n","  - **Person 7:** Located at left-down, very close to the dashcam, with an angle of -89.99 degrees. On road 0.\n","\n","**Potential Risks:**\n","- **Persons on Road and Sidewalk:** Persons 0, 1, 2, 3, 4, 5, 6, and 7 are on the road or sidewalk, posing a potential risk of collision.\n","- **Close Proximity to Dashcam:** All detected persons are very close to the dashcam, indicating a crowded and potentially dangerous situation.\n","\n","**Risk Evaluation:**\n","- **Person 0:** High (on road and sidewalks, very close to the dashcam, near 90-degree angle)\n","- **Person 1:** High (on road and sidewalks, very close to the dashcam, near -90-degree angle)\n","- **Person 2:** High (on road and sidewalks, very close to the dashcam, near -90-degree angle)\n","- **Person 3:** High (on road, very close to the dashcam, positive angle)\n","- **Person 4:** High (on road, very close to the dashcam, negative angle)\n","- **Person 5:** High (on road and sidewalk, very close to the dashcam, negative angle)\n","- **Person 6:** High (on road, very close to the dashcam, negative angle)\n","- **Person 7:** High (on road, very close to the dashcam, negative angle)\n","\n","The situation in Frame 0016 is critical, as all detected persons are on the road or sidewalks, very close to the dashcam, and at extreme angles. Immediate and cautious action is required to avoid potential collisions.\n"]}],"source":["messages = [\n","    get_sys_msg(sys_prompt),\n","    get_usr_msg(usr_prompt),\n","    {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {data}\"},\n","]\n","response = get_completion_from_messages(messages)"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["messages = [\n","    system_prompt,\n","    get_sys_msg(\"here is an example of analysis\"),\n","    {\"role\": \"user\", \"content\": f\"ChatGPT, here's the current road scenario data: {context}\"},\n","    {\"role\": \"assistant\", \"content\": \"Analyzing the road scenario data...\"},\n","    {\"role\": \"assistant\", \"content\": \"Based on my analysis, the context complexity is: `Medium` \\n\\n Here's the count of entities in the scene: \\n - **Persons**: 6 \\n - **Cars**: 2 \\n - **Bikes**: 1 \\n\\n Here are the danger levels for each person: \\n - **Person 0**: High \\n - **Person 1**: Low \\n - **Person 2**: Medium \\n\\n \"}\n","]\n"]},{"cell_type":"markdown","metadata":{},"source":["c"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"NameError","evalue":"name 'stop' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32md:\\#Courses Folder\\##大三\\SU23\\Summer_Research_2023\\Blind_LLM_Guide_Project\\Chatbot\\chatbot.ipynb Cell 18\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/chatbot.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m stop\n","\u001b[1;31mNameError\u001b[0m: name 'stop' is not defined"]}],"source":["stop"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["messages = [\n","    system_prompt,\n","    get_sys_msg(\"here is an example of analysis\"),\n","    {\"role\": \"user\", \"content\": f\"ChatGPT, here's the current road scenario data: {context}Analyzing the road scenario data\"},\n","]\n","response = get_completion_from_messages(messages)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = openai.Model.list()\n","print(response)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response['data']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = get_completion_from_messages(messages,\"gpt-3.5-turbo-16k-0613\",0.9)\n","messages.append(response)\n","messages.append(get_usr_msg(\"But there are no bike on the road\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["response = get_completion_from_messages(messages,\"gpt-3.5-turbo-16k-0613\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["messages"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_name = \"gpt-3.5-turbo-0613\"\n","\n","# Define the directory path\n","dir_path = './DINOmasked/'\n","\n","# Define the function to get completions\n","def get_completion_from_file(file_path, model=\"gpt-3.5-turbo\",temp = TEMPERATURE):\n","    with open(file_path, 'r') as file:\n","        prompt = file.read()\n","\n","    messages = [\n","        {\"role\": \"system\", \"content\": \"You are ChatGPT, a helpful assistant.\"},\n","        {\"role\": \"user\", \"content\": prompt},\n","    ]    \n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature=temp,\n","    )\n","    print(str(response.choices[0].message[\"content\"]))\n","    return response\n","\n","# Iterate over each directory within the specified path\n","for subdir, dirs, files in os.walk(dir_path):\n","    for file in files:\n","        # If the file is the one we're interested in\n","        if file.startswith('Info_Video_') and file.endswith('.txt'):\n","            input_file_path = os.path.join(subdir, file)\n","            print(f\"Processing file: {input_file_path}\")\n","\n","            # Get the GPT-3 response\n","            gpt_response = get_completion_from_file(input_file_path)\n","\n","            # Create a new file name for the output\n","            output_file_name = 'GPT_' + file\n","            output_file_path = os.path.join(subdir, output_file_name)\n","\n","            # Write the response to a new file\n","            with open(output_file_path, 'w') as file:\n","                file.write(\"Model used: \" + model_name + \"\\n\")\n","                file.write(\"Total tokens used: \" + str(gpt_response['usage']['total_tokens']) + \"\\n\")\n","                file.write(\"Response:\\n\" + gpt_response['choices'][0]['text'])\n","\n","            print(f\"Output written to: {output_file_path}\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_information(input_text):\n","    # Find the position of \"Therefore\" in the text\n","    index = input_text.find(\"Therefore\")\n","    \n","    # If \"Therefore\" is found, extract the text after it\n","    if index != -1:\n","        information_after_therefore = input_text[index:]\n","    else:\n","        information_after_therefore = \"Keyword 'Therefore' not found in the text.\"\n","\n","    return information_after_therefore\n","\n","def write_to_file(output_text, file_name='output.txt'):\n","    with open(file_name, 'w') as file:\n","        file.write(output_text)\n","\n","if __name__ == \"__main__\":\n","    # Read input text from a file\n","    with open('input.txt', 'r') as file:\n","        input_text = file.read()\n","\n","    # Extract the information after \"Therefore\"\n","    output_text = extract_information(input_text)\n","\n","    # Write the output to another text file\n","    write_to_file(output_text)\n","\n","    print(f\"Information after 'Therefore' has been written to {output_file_name}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["2. **Contextual Understanding:** Your chatbot should be capable of maintaining and updating a model of the car's surroundings based on this information. For example, it should keep track of the positions of other vehicles, pedestrians, and road features, updating these as new data comes in.\n","\n","3. **Real-Time Interaction:** The chatbot should be capable of generating responses in real-time. Delays could be dangerous in a driving context.\n","\n","4. **Proactive Alerting:** Your co-pilot chatbot should not just react to the driver's queries but should also proactively provide alerts and advice. For example, if it detects a pedestrian stepping onto the road, it should immediately alert the driver.\n","\n","5. **Simulated Training:** Consider using simulated environments to train and test your chatbot before deploying it in a real vehicle. This can help you ensure that the chatbot behaves correctly in a wide range of situations.\n","\n","6. **Safety Precautions:** Since the bot is serving in a co-pilot role, it should prioritize safety and assume the driver may be unaware of potential dangers. It should also be prepared to handle ambiguous situations by advising caution.\n","\n","7. **User Customization:** Different drivers may have different preferences for how much information they want to receive, what kind of language the co-pilot uses, etc. Consider allowing users to customize the chatbot's behavior to some extent.\n","\n","8. **Integration with Vehicle's Systems:** If possible, the chatbot could also be integrated with the vehicle's systems to provide even more functionality. For example, it could adjust the vehicle's speed or even take control in an emergency. However, this would require a high level of reliability and many legal and ethical considerations."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPUB/l//BFK5z5KaeV64uDe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
