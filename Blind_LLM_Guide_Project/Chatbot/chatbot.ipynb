{"cells":[{"cell_type":"markdown","metadata":{"id":"2dLdwEIy91QX"},"source":["# The Autonomous Vehicle Co-pilot\n","Here is a chatbot, empowered by GPT-3.5, running to help the vehicle driver. \n","\n","He is set as a co-pilot, analyzing the environment based on other multi-modality input, which has been processed as text so he can reason and identify potential risk. \n","\n","\n","## Setup\n","Notice: if you tried to run this program on your linux server, \n","and you are in China,\n","make sure that you opened the vpn. \n","Otherwise the api account may be forbiddened!"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7N8bvwlT98KX"},"outputs":[],"source":["import os\n","import openai\n","os.environ[\"http_proxy\"]=\"127.0.0.1:10080\"\n","os.environ[\"https_proxy\"]=\"127.0.0.1:10080\"\n","\n","def read_from_file(filepath):\n","    with open(filepath, 'r') as file:\n","        return file.read().strip()\n","\n","openai.api_key  = read_from_file('key/apikey.cn')\n","\n","TEMPERATURE = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OwMBRMRp9_ze"},"outputs":[],"source":["def get_completion(prompt, model=\"gpt-3.5-turbo-16k-0613\"):\n","    messages = [{\"role\": \"user\", \"content\": prompt}]\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature= TEMPERATURE, # this is the degree of randomness of the model's output\n","    )\n","    return response\n","    # return response.choices[0].message[\"content\"]\n","\n","def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\",temp = TEMPERATURE):\n","    response = openai.ChatCompletion.create(\n","        model=model,\n","        messages=messages,\n","        temperature= temp, # this is the degree of randomness of the model's output\n","    )\n","    # print(str(response.choices[0].message[\"content\"]))\n","    return response.choices[0].message[\"content\"]"]},{"cell_type":"markdown","metadata":{},"source":["## test on the api"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xQp3kZHr-JYL"},"outputs":[],"source":["blind_guide = \"\"\" \n","We are currently driving on a city street filled with green plants, with bicycle lanes on both sides of the road. On the left bicycle lane, there are three cyclists moving slowly, while on the right side, there are two cyclists riding at a faster pace.\n","Next, there is a spacious pedestrian walkway, with five pedestrians walking on the left side and four pedestrians on the right side, two of whom are jogging. Each side of the street is lined with banyan trees, providing ample shade for pedestrians to cool off.\n","We are heading towards an intersection. The traffic signal at the intersection is displaying a green light, indicating that we can proceed. Each direction at the intersection has only one lane, clearly marked. In front of us, there is a blue sedan driving at a moderate speed.\"\"\"\n","chat_history = [\n","    { 'role':'system','content': blind_guide},\n","    {'role':'system', 'content':'You are a co-pilot AI assistant designed to help drivers understand their surroundings.'},\n","    {'role':'user', 'content':'What is our current situation on the road?'},\n","]\n","\n","# test_reponse = get_completion_from_messages(chat_history)"]},{"cell_type":"markdown","metadata":{"id":"YGfYQGtK-Mb9"},"source":["# Data Integration\n"," Firstly, you'll need a way to convert the input from the vehicle's sensors (like LIDAR, RADAR, cameras, etc.) into a format that the chatbot can understand. This might involve using object detection algorithms to identify objects and their positions, then converting this data into a text description of the scene.\n","\n","\n","## buggy chatbot here\n","I need to find a good programming way of coding here"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SjeMn4Ae-N8t"},"outputs":[],"source":["# def chat_with_assistant(user_input, context):\n","#     # Append the user input to the context\n","#     context.append({'role':'user', 'content':f\"{user_input}\"})\n","    \n","#     # Get the assistant's response\n","#     response = get_completion_from_messages(context)\n","    \n","#     # Append the assistant's response to the context\n","#     context.append({'role':'assistant', 'content':f\"{response}\"})\n","    \n","#     return context\n","\n","\n","# # Chat with the assistant\n","# context = chat_with_assistant('Hello, assistant!', chat_history)\n","# print(context)\n","\n","# # Continue the conversation\n","# context = chat_with_assistant('Tell me a joke', context)\n","# print(context)\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["ChatGPT, based on the incoming road scenario data, I need you to assess the situation and provide us with critical information. \n","## input\n","The road scenario data will be provided in {'context'}, it contains the continuous frame information of video from dashcam in the vehicle. The autonomous system provides you with information on road layout, people's locations, their distances and angles from the dashcam, the surfaces they are on, and the confidence level of each detection.\n","## output \n","Your analysis should provide:\n","- an understanding of the context complexity (low, medium, or high), \n","- the number of persons, cars, and bikes present in the scene, \n","- an array detailing the danger level for each person, if applicable.\n","The output should be markdown format\n","\n","This analysis should be grounded in the current context and make predictions for the short term future to assist in autonomous driving. The key goal here is to identify potential risks to enhance the safety and efficiency of our journey."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\n"]},{"cell_type":"markdown","metadata":{},"source":["\"You are a co-pilot AI designed to analyze road scenario data and provide critical information about the situation. Based on the video frames from the dashcam and the data provided by the autonomous system, you will assess the context complexity, count the number of persons, cars, and bikes in the scene, and evaluate the danger level for each person. Your goal is to identify potential risks to enhance the safety and efficiency of the journey. The output should be in markdown format."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["sys_prompt = read_from_file(\"key/sys_prompt.md\")\n","usr_prompt = read_from_file(\"key/usr_prompt.md\")\n","\n","def get_sys_msg(content:str): \n","    system_msg = {\"role\": \"system\", \"content\": content}\n","    return  system_msg\n","def get_usr_msg(content:str): \n","    msg = {\"role\": \"user\", \"content\": content}\n","    return msg\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["data = \"\"\"INFO of 0016:\n","road 0 is at middle_down\n","sidewalk 1 is at right_down\n","sidewalk 2 is at right_down\n","person 0 is at middle_down\n","The [distance,angle] from person 0 to our dashcam is: [very close,89.97960036997033]\n","person 1 is at left_down\n","The [distance,angle] from person 1 to our dashcam is: [very close,-89.98811258767391]\n","person 2 is at left_down\n","The [distance,angle] from person 2 to our dashcam is: [very close,-89.98749824583163]\n","person 3 is at middle_down\n","The [distance,angle] from person 3 to our dashcam is: [very close,89.96852785395733]\n","person 4 is at left_down\n","The [distance,angle] from person 4 to our dashcam is: [very close,-89.99328360812777]\n","person 5 is at left_down\n","The [distance,angle] from person 5 to our dashcam is: [very close,-89.99173842984247]\n","person 6 is at left_down\n","The [distance,angle] from person 6 to our dashcam is: [very close,-89.99199265188705]\n","person 7 is at left_down\n","The [distance,angle] from person 7 to our dashcam is: [very close,-89.99241327380344]\n","Person 0 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [1151.6272   683.91156 1259.8259  1029.4976 ]\n","Person 1 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [520.33466 722.2189  556.2974  830.36035]\n","Person 2 is on the road 0, sidewalk 1, sidewalk 2,his/her bbox is [544.58014 737.0274  573.4954  827.68024]\n","Person 3 is on the road 0,his/her bbox is [1110.2614  723.2576 1128.289   741.3161]\n","Person 4 is on the road 0,his/her bbox is [205.18512 686.6346  222.12915 713.3797 ]\n","Person 5 is on the road 0, sidewalk 1,his/her bbox is [343.09924 702.2559  363.39508 733.56   ]\n","Person 6 is on the road 0,his/her bbox is [324.6748  691.9793  343.29242 718.48505]\n","Person 7 is on the road 0,his/her bbox is [291.81046 690.33636 306.7418  715.5451 ]\n","number of Surface mask, Road&sidewalk, People 's mask, actural people: (9, 3, 9, 8)\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["messages = [\n","    get_sys_msg(sys_prompt),\n","    get_usr_msg(usr_prompt),\n","    {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {data}\"},\n","]\n","# response = get_completion_from_messages(messages)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{},"source":["Great, now I have a working chatGPT api as below:{{{\n","messages = [\n","    get_sys_msg(sys_prompt),\n","    get_usr_msg(usr_prompt),\n","    {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {frame_data}\"},\n","]\n","response = get_completion_from_messages(messages)\n","}}}\n","For raw data stored in folder raw_data/ , there are info of video as below:\n","- raw_data/Info_Video_0001.txt\n","- raw_data/Info_Video_0002.txt\n","...\n","### task: I want you provide a double for-loop for me, here is the pesudo code:\n","\n","for all the Info txt in raw_data folder{\n","    for each frame in the txt{\n","        read the frame info into variable 'frame_data'\n","        response = get_completion_from_messages\n","        append the response into 'LLM_data/Result_Video_xxxx', here the xxxx is current video id\n","    }\n","}\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_frames_from_raw_file(file_path):\n","    frames = []\n","    current_frame_data = ''\n","    reading_frame = False\n","\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.startswith('INFO of'):\n","                if reading_frame:\n","                    frames.append(current_frame_data.strip())\n","                    current_frame_data = ''\n","                reading_frame = True\n","\n","            if reading_frame:\n","                current_frame_data += line\n","\n","    # Adding the last frame if any\n","    if current_frame_data:\n","        frames.append(current_frame_data.strip())\n","\n","    return frames\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import os\n","import re\n","from pathlib import Path\n","\n","raw_data_folder = \"raw_data/\"\n","\n","output_folder = \"LLM_data/\"\n","\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","for filename in os.listdir(raw_data_folder):\n","    if filename.startswith(\"Info_Video_\") and filename.endswith(\".txt\"):\n","        # the id may be 'bd99', '0001', 'eb61'\n","        video_id = filename[-8:-4]\n","        output_path = Path(f\"LLM_data/Result_Video_{video_id}.txt\")\n","        \n","        frames = read_frames_from_raw_file(os.path.join(raw_data_folder, filename))\n","        start_frame = 0\n","        if output_path.exists():\n","            print(f\"Already handled {output_path}\")\n","            # Read the existing frames that have been processed\n","            # with open(output_path, 'r') as result_file:\n","            #     processed_frames = re.findall(r'### Frame (\\d{4}) Analysis', result_file.read())\n","            #     start_frame = len(processed_frames) # Start from the next unprocessed frame\n","            #     frames = frames[start_frame:] # Excl\n","            #     if frames is None:\n","            #         continue\n","            continue\n","        with open(os.path.join(raw_data_folder, filename), 'r') as raw_file:\n","            with open(os.path.join(output_folder, f\"Result_Video_{video_id}.txt\"), 'a') as result_file:\n","                print(f\"Analyzing video {video_id} starting from frame {start_frame}\")\n","\n","                for frame_data in frames:\n","                    messages = [\n","                        get_sys_msg(sys_prompt), \n","                        get_usr_msg(usr_prompt), \n","                        {\"role\": \"user\", \"content\": f\"here's the current road scenario data: {frame_data}\"},\n","                    ]\n","                    response = get_completion_from_messages(messages)\n","                    \n","                    result_file.write(response + '\\n')\n","                    \n","        print(f\"Analysis completed for video {video_id}\")\n","\n","print(\"All videos processed!\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_frames_from_mot_record(file_path, frames_per_segment=5):\n","    segments = []\n","    current_segment_data = ''\n","    frame_count = 0\n","    delimiter = \"=====================================================\"\n","\n","    with open(file_path, 'r') as file:\n","        for line in file:\n","            if line.startswith('At frame'):  # assuming each new frame starts with 'At frame'\n","                frame_count += 1\n","                \n","            if line.strip() == delimiter:\n","                continue  # skip delimiter lines\n","\n","            current_segment_data += line\n","\n","            if frame_count == frames_per_segment:\n","                segments.append(current_segment_data.strip())\n","                current_segment_data = ''\n","                frame_count = 0\n","\n","    # Adding the last segment if any\n","    if current_segment_data:\n","        segments.append(current_segment_data.strip())\n","\n","    return segments\n","\n","seg = read_frames_from_mot_record(\"mot_archive_0828/mot_car_b1c9c847-3bda4659.txt\")\n","seg"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def read_file(file_path):\n","\n","    with open(file_path, 'r') as file:\n","        return file\n"]},{"cell_type":"code","execution_count":26,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["At frame 4, car 1 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 2 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 3 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 8 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 9 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 5 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, person 4 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, truck 7 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, person 6 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 10 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n","At frame 4, car 11 is located at coordinates [361.46, 292.77] with a bounding box of width 403.93 and height 284.62.\n"," \n"]}],"source":["def read_frames_from_mot_record(file_path, frames_per_segment=5):\n","    \"\"\"\n","    Splits the text into segments, each containing data for a specified number of frames.\n","    \"\"\"\n","    # Splitting the text by the starting phrase 'At frame '\n","    with open(file_path, 'r') as file:\n","        text = file.read()\n","\n","    sentences = text.split('At frame ')\n","    \n","    segments = []\n","    current_segment = []\n","    current_frame = None\n","    \n","    for sentence in sentences:  \n","        # Extract frame number from the sentence\n","        frame_num = int(sentence.split(',')[0].split(' ')[0])\n","        \n","        # If current frame is None or is the same as the last frame, continue appending to the current segment\n","        if current_frame is None or frame_num == current_frame:\n","            current_segment.append('At frame ' + sentence)\n","        else:\n","            # If the frame number has changed, append the current segment to segments and start a new one\n","            segments.append('\\n'.join(current_segment))\n","            current_segment = ['At frame ' + sentence]\n","        \n","        current_frame = frame_num\n","\n","        # If the length of the current segment reaches the specified frames_per_segment, append it to segments\n","        if len(set([int(s.split(' ')[2].split(',')[0]) for s in current_segment])) == frames_per_segment:\n","            # segments.append('\\n'.join(current_segment))\n","            current_segment = []\n","\n","    # Append any remaining data to segments\n","    if current_segment:\n","        segments.append('\\n'.join(current_segment))\n","\n","    return segments\n","\n","# Segment the content using the improved function\n","improved_segments_v2 = read_frames_from_mot_record(\"mot_archive_0828/mot_car_b1c9c847-3bda4659.txt\")\n","len(improved_segments_v2), improved_segments_v2[0], improved_segments_v2[1]  # Displaying the length and the first two segments for verification\n","\n","print(improved_segments_v2[4])\n"]},{"cell_type":"markdown","metadata":{},"source":["这个是干什么的，我忘记为什么写他了"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["\"Based on the following sequence of frames, provide a concise description of the road scene, capturing significant events or movements of people and vehicles:\"\n"]},{"cell_type":"markdown","metadata":{},"source":[]},{"cell_type":"markdown","metadata":{},"source":["c"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def extract_information(input_text):\n","    # Find the position of \"Therefore\" in the text\n","    index = input_text.find(\"Therefore\")\n","    \n","    # If \"Therefore\" is found, extract the text after it\n","    if index != -1:\n","        information_after_therefore = input_text[index:]\n","    else:\n","        information_after_therefore = \"Keyword 'Therefore' not found in the text.\"\n","\n","    return information_after_therefore\n","\n","def write_to_file(output_text, file_name='output.txt'):\n","    with open(file_name, 'w') as file:\n","        file.write(output_text)\n","\n","if __name__ == \"__main__\":\n","    # Read input text from a file\n","    with open('input.txt', 'r') as file:\n","        input_text = file.read()\n","\n","    # Extract the information after \"Therefore\"\n","    output_text = extract_information(input_text)\n","\n","    # Write the output to another text file\n","    write_to_file(output_text)\n","\n","    print(f\"Information after 'Therefore' has been written to {output_file_name}\")\n"]},{"cell_type":"markdown","metadata":{},"source":["2. **Contextual Understanding:** Your chatbot should be capable of maintaining and updating a model of the car's surroundings based on this information. For example, it should keep track of the positions of other vehicles, pedestrians, and road features, updating these as new data comes in.\n","\n","3. **Real-Time Interaction:** The chatbot should be capable of generating responses in real-time. Delays could be dangerous in a driving context.\n","\n","4. **Proactive Alerting:** Your co-pilot chatbot should not just react to the driver's queries but should also proactively provide alerts and advice. For example, if it detects a pedestrian stepping onto the road, it should immediately alert the driver.\n","\n","5. **Simulated Training:** Consider using simulated environments to train and test your chatbot before deploying it in a real vehicle. This can help you ensure that the chatbot behaves correctly in a wide range of situations.\n","\n","6. **Safety Precautions:** Since the bot is serving in a co-pilot role, it should prioritize safety and assume the driver may be unaware of potential dangers. It should also be prepared to handle ambiguous situations by advising caution.\n","\n","7. **User Customization:** Different drivers may have different preferences for how much information they want to receive, what kind of language the co-pilot uses, etc. Consider allowing users to customize the chatbot's behavior to some extent.\n","\n","8. **Integration with Vehicle's Systems:** If possible, the chatbot could also be integrated with the vehicle's systems to provide even more functionality. For example, it could adjust the vehicle's speed or even take control in an emergency. However, this would require a high level of reliability and many legal and ethical considerations."]}],"metadata":{"colab":{"authorship_tag":"ABX9TyPUB/l//BFK5z5KaeV64uDe","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":0}
