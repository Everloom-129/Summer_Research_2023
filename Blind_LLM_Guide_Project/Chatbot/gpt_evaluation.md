# Evaluation on the GPT 

关于如何判断gpt 效果的手册

2023年8月27日



## JAAD vs BDD

随着数据集的内涵不一样，GPT得出的推理效果也不尽相同。因此我们有必要分析一下他在不同场景下的判断能力，好针对性的prompt engineering

- JAAD **15**: 多行人，交叉特别多，车速慢，情况复杂，视频短（5~30s)
- BDD **10**: 单行人场景多，车速快，行人突发状况也有，复杂度也Ok, 视频长（30s+)

这是我们基于“肉眼观察”的 **先验知识,** 给gpt prompt / 建模指导的过程，就是将先验知识植入COT的过程。

因此，针对我们挑选出来的10+15条视频，我们需要做的是：

1. 设置groundtruth, 这需要找经验丰富的司机对着目标追踪的视频看，可以考虑在主实验做完后，增加一个环节，让被试对着目标追踪视频标记自身认为需要注意的id，将这个id list 记录下来，后续做data analysis @ZTY

   > 例子：
   >
   > | 被试 | 视频      | id(only high risk) | 描述（这个部分汇总之后可以输给GPT做数据处理，可以写在论文里/ 作为例子输入给GPT） |
   > | ---- | --------- | ------------------ | ------------------------------------------------------------ |
   > | WJ   | video0194 | 12, 15, 19         | 12横穿马路                                                   |
   > | WJ   | video0233 | 10, 85, 101,111    | 85在玩耍，111在飞                                            |
   > | ZQ   | video0194 | 12, 13, 19         | 12，13 在横穿马路                                            |
   >
   > ...

   **目的在于：论证LLM作为Agent的有效性**

   

   速度：可以模糊

   由人标注汽车速度

   【模糊性输入】

   加速，直行，减速

   

   

   

   

   > 论文：10%以上认为有风险即有风险

2. **总结一个列表出来：**

   - 所有视频的天气，行人复杂度（低中高）
   - 突发情况（关键帧），即 1 中，由司机分析出为什么这个场景重要
     - 可以引申出对自动驾驶corner case的分析
     - 记录下这个突发情况的时间

   > 例子： f == frame
   >
   > video 0194: 12.5s / 375 f 有行人横穿马路
   >
   > video 0233: 5s / 150 f 有小孩在马路旁玩耍
   
   - 车辆自身属性：
   
     - 直行
     - 转弯
     - 急刹
   
   - 路况属性
   
     - 工地
     - 十字路口
   
   - 我们的思路应该转变，假设我们是在分析十几个视频，我们不应该让我们这里获得所有信息，交给GPT 当driving agent, 他应该可以获得车内驾驶信息, 好更多推断
   
     （类似LMC说服的早期demo）

> 例子：
>
> to be continue


3. 对比类似场景：

   两个数据集，找类似的场景，比方说：

   - 直行，十字路口，晴朗，行人横穿马路

   

   将这两个视频的信息输给GPT(raw data+ obj track)， 看看判断的情况会不会有变化
   
   
   
   - [ ] 给一个prompt 讲解如何对比
   
   
   
   
   
   - 

## Criterion

to be continue...

- [ ] 典型的例子展示



