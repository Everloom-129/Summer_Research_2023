{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# vision text data NLP \n",
    "Tony 08/12/2023\n",
    "\n",
    "Input:\n",
    "- raw data from my detect_road module\n",
    "- chatGPT generated analysis result\n",
    "\n",
    "Output:\n",
    "- bbox json of specific video \n",
    "- risk json of specific video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INFO of frame 0001:\\nroad 0 is at middle_down\\nsidewalk 1 is at right_down\\nperson 0 is at middle_down\\nThe [distance,angle] of person 0 is: [very close,slightly to the right]\\ncar 1 is at right_down\\n<V> car 1 is at [1113.8364  692.2208 1457.0139  925.9918] <VE> \\nperson 2 is at left_down\\nThe [distance,angle] of person 2 is: [very close,None]\\nperson 3 is at left_down\\nThe [distance,angle] of person 3 is: [very close,None]\\nperson 4 is at middle_down\\nThe [distance,angle] of person 4 is: [very close,None]\\nPerson 0 is on the road 0, sidewalk 1, his/her bbox is[1172.3464   659.84393 1211.4929   705.81586]\\nPerson 2 is on the road 0, sidewalk 1, his/her bbox is[288.8023  655.01025 308.0401  702.405  ]\\nPerson 3 is on the road 0, his/her bbox is[620.4963  704.68494 631.8676  736.1472 ]\\nPerson 4 is not on any detected surface, his/her bbox is[643.36334 709.2158  660.0417  760.1974 ]\\nINFO of frame 0002:\\nroad 0 is at middle_down\\ncar 0 is at right_down\\n<V> car 0 is at [1342.1464   697.75653 1919.4899  107'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the content of the uploaded file to understand the key frame information\n",
    "file_path = \"raw_data/Info_Video_0194.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    key_frame_data = file.read()\n",
    "\n",
    "# Displaying the first 1000 characters to get an overview of the content\n",
    "key_frame_data[:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'### Frame 0001 Analysis\\n\\n**Summary of Key Frame Information:**\\n- **Road Position:** The road (road 0) is located in the middle-down region of the frame.\\n- **Sidewalk Position:** The sidewalk (sidewalk 1) is located in the right-down region of the frame.\\n- **People Positions and Distances:**\\n  - **Person 0:** Located at middle-down, very close to the dashcam, slightly to the right. On road 0, sidewalk 1.\\n  - **Person 2:** Located at left-down, very close to the dashcam. On road 0, sidewalk 1.\\n  - **Person 3:** Located at left-down, very close to the dashcam. On road 0.\\n  - **Person 4:** Located at middle-down, very close to the dashcam. Not on any detected surface.\\n\\n**Potential Risks:**\\n- **Persons on Road and Sidewalk:** Persons 0, 2, 3 are on the road or sidewalk, posing a potential risk of collision.\\n- **Close Proximity to Dashcam:** All detected persons are very close to the dashcam, indicating a crowded and potentially dangerous situation.\\n- **Non-Detected Surfaces:** Person 4 is n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's read the content of the LLM generated file and load into JSON\n",
    "file_path = \"LLM_data/Result_Video_0194.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    result_data = file.read()\n",
    "\n",
    "# Displaying the first 1000 characters to get an overview of the content\n",
    "result_data[:1000]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据筛选清单处理\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Given content of the \"video_human_selection.txt\" file\n",
    "content = \"\"\"\n",
    "b1c9c847-3bda4659     1 10 12  19\n",
    "b1d10d08-c35503b8     7 10 83 90\n",
    "b1d22ed6-f1cac061       12 29 38 36 35 52 51 66 67 68  77 78 100 107 104 105 157 153 162 163 166 173 181 186 176 160 194 197 170 186 234 236 250 251  295 304 309 295 324 293 357 368 413 415     \n",
    "b1dac7f7-6b2e0382      1 8 49\n",
    "b1f4491b-33824f31       4 36  43 44 77  119 120 169 166 170 167 185 209 235\n",
    "b2ae0446-4b0bfda7      none\n",
    "b2be7200-b6f7fe0a       1 2 6 13  22 26 29 28 31 34 39 66 67\n",
    "b2bee3e1-80c787bd      2 6  12 \n",
    "b2d22b2f-8302eb61       18  44 46 47  51 55  62 63 \n",
    "b2d502aa-f0b28e3e      12 16  29 30 33\n",
    "b4542860-0b880bb4      93  240 270  265  295 314 307\n",
    "cd09a73f-5f6b9212        1  12\n",
    "cd17ff29-f393274e         1 2 3 4  25 31  37   47 49 68\n",
    "cd26264b-22001629       2 8  19 47 24 26  12 13 57 9 43 18  46 45  18 43 45 24 48 96 97 107 109 127 151 153\n",
    "\"\"\"\n",
    "import json\n",
    "# Process content and convert to desired JSON structure\n",
    "video_selection = {}\n",
    "for line in content.strip().split(\"\\n\"):\n",
    "    parts = line.split()\n",
    "    video_name = parts[0]\n",
    "    if parts[1] == \"none\":\n",
    "        ids = []\n",
    "    else:\n",
    "        ids = [int(pid) for pid in parts[1:]]\n",
    "    video_selection[video_name] = ids\n",
    "\n",
    "def save_as_json(json_data, json_file_path):\n",
    "    \"\"\"Save data as a JSON file.\"\"\"\n",
    "    with open(json_file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=4)\n",
    "\n",
    "save_as_json(video_selection, \"human_select.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Process content and convert to desired JSON structure\n",
    "video_selection = {}\n",
    "for line in content.strip().split(\"\\n\"):\n",
    "    parts = line.split()\n",
    "    video_name = parts[0]\n",
    "    if parts[1] == \"none\":\n",
    "        ids = []\n",
    "        persons_data = {}\n",
    "    else:\n",
    "        ids = [int(pid) for pid in parts[1:]]\n",
    "        persons_data = {str(pid): {\"starting_frame\": None, \"ending_frame\": None} for pid in ids}\n",
    "    \n",
    "    video_data = {\n",
    "        \"ids\": ids\n",
    "    }\n",
    "    video_data.update(persons_data)\n",
    "    video_selection[video_name] = video_data\n",
    "\n",
    "\n",
    "save_as_json(video_selection, \"human_select_interval.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_small_bbox(bbox):\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    width = x2 - x1\n",
    "    height = y2 - y1\n",
    "\n",
    "    # You can adjust these thresholds as needed\n",
    "    width_threshold = 5.0\n",
    "    height_threshold = 5.0\n",
    "\n",
    "    return width < width_threshold or height < height_threshold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>()>,\n",
       "            {'0001': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1172.3464, 659.84393, 1211.4929, 705.81586],\n",
       "                           2: [288.8023, 655.01025, 308.0401, 702.405],\n",
       "                           3: [620.4963, 704.68494, 631.8676, 736.1472],\n",
       "                           4: [643.36334, 709.2158, 660.0417, 760.1974]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [1113.8364, 692.2208, 1457.0139, 925.9918]})},\n",
       "             '0002': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [633.6151, 712.92944, 654.3307, 770.7612]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1342.1464, 697.75653, 1919.4899, 1075.8792],\n",
       "                           2: [470.33676, 710.5024, 595.43134, 758.7325]})},\n",
       "             '0003': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1409.032, 638.32294, 1469.0991, 720.14886],\n",
       "                           1: [631.18536, 693.3739, 652.3934, 759.5343],\n",
       "                           3: [1338.0068, 653.7236, 1389.8274, 724.0175],\n",
       "                           4: [650.8084, 706.17365, 668.0578, 759.09393],\n",
       "                           8: [317.90494, 665.7386, 335.23508, 691.58563]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1243.6072, 718.215, 1673.1765, 1035.1912],\n",
       "                           5: [456.39972, 691.5774, 597.0412, 745.6482],\n",
       "                           6: [313.57886, 676.35706, 445.94635, 740.1216],\n",
       "                           7: [1013.083, 708.86096, 1274.8462, 885.26965]})},\n",
       "             '0004': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [227.46501, 656.5088, 267.38333, 747.0757],\n",
       "                           1: [649.82153, 691.9147, 669.7656, 763.62634],\n",
       "                           2: [624.28455, 685.1283, 649.4254, 763.5648]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {})},\n",
       "             '0005': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [165.90472, 672.1409, 202.23483, 774.4611],\n",
       "                           3: [112.371666, 655.4974, 138.04819, 723.561],\n",
       "                           5: [638.3156, 725.34247, 658.96356, 789.33685]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [1208.7572, 720.6627, 1918.8068, 1078.4926],\n",
       "                           2: [219.73212, 689.4193, 392.75555, 765.1167],\n",
       "                           4: [416.44492, 708.0679, 585.4302, 771.44604]})},\n",
       "             '0006': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [100.416306, 635.4571, 144.68259, 746.3824],\n",
       "                           1: [1025.3455, 645.22, 1118.5796, 848.48083],\n",
       "                           2: [45.59276, 625.725, 73.017784, 707.8154],\n",
       "                           3: [586.2195, 669.9249, 612.1697, 758.552],\n",
       "                           4: [613.1933, 675.5683, 636.5538, 756.59955],\n",
       "                           8: [0.18210888, 640.96753, 29.375076, 728.68127]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {5: [1354.9849, 659.68677, 1919.4897, 1078.7059],\n",
       "                           6: [165.82236, 653.7776, 351.08237, 735.3733],\n",
       "                           7: [379.8786, 670.5248, 562.2373, 738.489]})},\n",
       "             '0007': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1077.3182, 652.0559, 1153.3444, 904.46716],\n",
       "                           1: [50.60933, 651.0512, 92.57283, 765.67804],\n",
       "                           2: [0.013030052, 638.16248, 17.277203, 728.6665],\n",
       "                           3: [329.08774, 668.9827, 356.14395, 740.23737]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {4: [124.53485, 669.8729, 316.9377, 756.8612],\n",
       "                           5: [345.99915, 688.55, 541.461, 761.4189]})},\n",
       "             '0008': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1105.6877, 657.0222, 1200.6599, 952.1293],\n",
       "                           1: [12.617321, 648.9849, 56.19589, 766.1988],\n",
       "                           3: [542.6715, 699.2037, 573.30286, 798.0391],\n",
       "                           5: [571.3445, 712.7883, 596.93713, 796.7274]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [91.620346, 672.1418, 288.43384, 764.0607],\n",
       "                           4: [318.44424, 695.5043, 526.08624, 771.9972],\n",
       "                           6: [612.4722, 707.7593, 725.53937, 791.48645]})},\n",
       "             '0009': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1128.2292, 671.54156, 1234.093, 1001.41656],\n",
       "                           1: [535.30774, 716.9983, 566.03796, 820.0359],\n",
       "                           4: [555.9732, 726.2064, 583.7387, 817.0128]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [67.09684, 684.8155, 269.84802, 780.79047],\n",
       "                           3: [305.9153, 710.9074, 514.3607, 791.1762],\n",
       "                           5: [602.1182, 726.0665, 719.8265, 812.4105]})},\n",
       "             '0010': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1142.7616, 678.1879, 1250.8558, 1021.0838]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [47.62439, 685.4393, 253.0552, 784.8172],\n",
       "                           2: [292.68573, 714.27905, 505.0122, 797.13135],\n",
       "                           3: [1144.1792, 726.04645, 1623.2981, 1017.998],\n",
       "                           4: [594.73346, 731.32135, 715.53143, 820.9306]})},\n",
       "             '0011': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1154.1536, 681.0327, 1260.9319, 1029.5857],\n",
       "                           3: [517.41895, 723.75476, 553.0541, 830.9574],\n",
       "                           4: [542.4781, 739.8944, 572.84894, 827.9431],\n",
       "                           7: [206.56114, 686.0537, 223.35252, 712.9756]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [35.059883, 686.8364, 241.8689, 787.1006],\n",
       "                           2: [283.23627, 715.2337, 499.37292, 799.2034],\n",
       "                           5: [589.2305, 732.14716, 713.0479, 823.153],\n",
       "                           6: [1158.9846, 720.2052, 1670.1311, 1038.3804]})},\n",
       "             '0012': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1133.1692, 687.8288, 1240.8611, 1019.5799]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [275.59515, 714.1817, 493.9557, 798.9327],\n",
       "                           2: [25.6484, 683.5206, 234.69211, 785.89734],\n",
       "                           3: [1172.8173, 725.44116, 1702.9982, 1049.1323],\n",
       "                           4: [584.3594, 732.03375, 711.6127, 823.639]})},\n",
       "             '0013': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1117.6968, 694.7267, 1213.938, 1006.2936],\n",
       "                           4: [508.27307, 720.13513, 544.4498, 831.63245]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [271.79782, 712.7221, 492.29953, 798.75507],\n",
       "                           2: [21.634277, 682.1, 230.61519, 784.8999],\n",
       "                           3: [1184.2136, 725.8141, 1723.1455, 1055.6299],\n",
       "                           5: [581.51746, 731.3501, 710.36255, 823.7477]})},\n",
       "             '0014': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1119.7068, 696.3329, 1199.509, 984.99],\n",
       "                           1: [0.20336342, 675.92981, 21.829554, 798.81311]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [268.91867, 712.32135, 490.6226, 797.66473]})},\n",
       "             '0015': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1078.4005, 700.9148, 1186.0775, 967.00684],\n",
       "                           1: [6.3595057, 674.84357, 36.37578, 797.51654]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1183.4641, 723.7442, 1740.1497, 1058.8274]})},\n",
       "             '0016': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [26.80541, 677.9602, 59.00949, 797.64954],\n",
       "                           1: [1089.3325, 703.80316, 1174.9937, 952.3526]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1187.6887, 722.2989, 1755.2837, 1067.0602]})},\n",
       "             '0017': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [37.35466, 674.85474, 72.11809, 791.7434],\n",
       "                           1: [1071.1848, 698.9427, 1166.3677, 936.16705]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1192.5192, 718.17346, 1780.6967, 1058.0259]})},\n",
       "             '0018': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1054.4261, 692.4637, 1138.7872, 921.06854],\n",
       "                           3: [909.2571, 729.4945, 933.1793, 809.1084]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [1195.5802, 711.0464, 1815.91, 1060.868],\n",
       "                           2: [1015.44305, 728.11084, 1259.8359, 876.3922]})},\n",
       "             '0019': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1028.1482, 693.3439, 1105.6038, 916.14685],\n",
       "                           1: [890.9222, 729.287, 915.62787, 810.5868],\n",
       "                           2: [1164.2986, 704.5046, 1193.155, 743.2138]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {3: [1200.1672, 710.62476, 1864.3875, 1062.2423],\n",
       "                           4: [1006.1208, 726.638, 1250.8947, 874.6851],\n",
       "                           5: [551.3863, 716.82513, 675.91144, 815.51776]})},\n",
       "             '0020': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1005.61646, 688.5166, 1083.6057, 912.0211],\n",
       "                           1: [0.21813583, 659.11938, 42.804279, 777.44666],\n",
       "                           2: [1169.8278, 699.7501, 1199.9283, 738.71094],\n",
       "                           5: [463.46686, 718.31683, 495.04987, 816.50885]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {3: [167.36288, 685.142, 401.7507, 780.2552],\n",
       "                           4: [1223.9309, 709.50824, 1919.1038, 1077.0994]})},\n",
       "             '0021': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [977.724, 681.07074, 1064.9996, 907.93915],\n",
       "                           1: [3.125576, 654.2858, 36.61104, 776.1059],\n",
       "                           2: [407.77036, 687.4956, 446.80826, 818.15063],\n",
       "                           5: [440.2515, 709.2879, 481.06955, 814.5618]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {3: [0.42404938, 649.34503, 117.81665, 758.87091],\n",
       "                           4: [140.11967, 677.4852, 383.62097, 775.43713]})},\n",
       "             '0022': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [963.55963, 684.10394, 1052.011, 915.4554],\n",
       "                           1: [1200.5272, 693.5425, 1237.0006, 733.5298],\n",
       "                           2: [13.80097, 657.28906, 50.791893, 786.3159],\n",
       "                           3: [381.92575, 692.5312, 426.1617, 828.5279]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {4: [114.99211, 680.8929, 363.99115, 782.1308],\n",
       "                           5: [0.24562836, 650.89307, 89.754929, 767.06592]})},\n",
       "             '0023': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [957.19214, 677.559, 1040.9822, 913.05035],\n",
       "                           1: [22.638485, 653.0871, 57.132656, 788.9476],\n",
       "                           2: [353.0538, 681.8723, 398.52097, 829.1378]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {})},\n",
       "             '0024': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [952.34894, 679.6991, 1041.2037, 920.323],\n",
       "                           1: [1242.4221, 687.2799, 1282.8884, 733.4707],\n",
       "                           2: [25.161716, 656.11365, 66.661575, 793.9365],\n",
       "                           5: [318.65472, 684.3345, 367.72412, 836.8906]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {3: [1035.2893, 721.7135, 1408.3301, 947.37805],\n",
       "                           4: [1512.2764, 770.5052, 1919.5891, 1078.9899]})},\n",
       "             '0025': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [941.2748, 680.3653, 1032.0769, 927.42474],\n",
       "                           1: [28.288637, 677.1665, 75.38621, 810.2095]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1040.1123, 721.94464, 1461.2571, 972.54425]})},\n",
       "             '0026': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [945.45776, 682.7697, 1036.1362, 933.94293],\n",
       "                           2: [890.37335, 721.60864, 932.7172, 857.5476]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [1049.7251, 728.07837, 1523.5571, 1004.3734]})},\n",
       "             '0027': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [948.9938, 688.2161, 1040.6952, 942.36285],\n",
       "                           2: [32.575993, 676.9814, 88.56059, 822.78033]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1062.4845, 732.71606, 1599.1359, 1043.8536]})},\n",
       "             '0028': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1387.1544, 676.5996, 1436.3322, 739.944],\n",
       "                           1: [966.9823, 686.2904, 1060.1943, 946.2406]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1081.7896, 733.0689, 1696.3972, 1067.6296]})},\n",
       "             '0029': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [988.2317, 689.63666, 1087.823, 954.17694],\n",
       "                           1: [922.8839, 728.89984, 986.2196, 902.68524],\n",
       "                           2: [1461.0392, 674.4579, 1520.0262, 745.11487]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {3: [1118.8413, 737.3346, 1835.7871, 1078.6388],\n",
       "                           4: [906.94434, 703.18225, 1216.1436, 891.4053],\n",
       "                           5: [0.49116516, 676.72455, 499.38098, 1042.2472]})},\n",
       "             '0030': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1056.9673, 691.46075, 1159.2976, 971.2806],\n",
       "                           1: [975.4293, 733.19763, 1060.3276, 928.51]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [1206.1132, 736.4462, 1919.0118, 1079.0288]})},\n",
       "             '0031': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1191.9469, 688.7831, 1312.2958, 1010.54285],\n",
       "                           1: [1085.6243, 735.3646, 1180.456, 969.6831]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [253.58061, 704.3688, 589.3563, 925.24744]})},\n",
       "             '0032': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1252.1107, 742.3878, 1349.796, 1064.3478],\n",
       "                           1: [1432.4523, 681.3373, 1576.7213, 1075.3866]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {2: [118.79756, 708.1899, 580.2651, 999.36847]})},\n",
       "             '0033': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {3: [1594.8403, 717.25024, 1795.6682, 1007.64417]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1107.5162, 734.93274, 1278.2914, 848.7273],\n",
       "                           1: [1303.8815, 654.2183, 1919.5785, 1034.3833],\n",
       "                           2: [0.48327637, 658.81152, 451.44086, 1036.0946]})},\n",
       "             '0034': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [59.13186, 651.39734, 89.73945, 732.94324],\n",
       "                           2: [303.27344, 667.1163, 325.34833, 738.66547],\n",
       "                           3: [6.684243, 660.9258, 21.505646, 710.14734]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1129.4977, 748.5049, 1360.504, 890.2468]})},\n",
       "             '0035': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [1035.1548, 722.90027, 1053.9971, 776.4679]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1171.2883, 751.4605, 1533.8635, 958.4637]})},\n",
       "             '0036': {'person': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {1: [1005.1946, 703.9678, 1025.3428, 765.03394]}),\n",
       "              'car': defaultdict(<function __main__.parse_raw_data.<locals>.<lambda>.<locals>.<lambda>()>,\n",
       "                          {0: [1294.2627, 736.7109, 1919.7744, 1071.7036]})}})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import re\n",
    "# Function to parse the raw json_data and extract the relevant information\n",
    "\n",
    "# Person 0 is on the road 0, sidewalk 1,his/her bbox is [1148.4463   625.3968  1183.7595   663.28143]\n",
    "# <V> car 1 is at [ 28.309494 712.38245  192.96992  777.90173 ] <VE> \n",
    "def parse_raw_data(json_data):\n",
    "    frames = defaultdict(lambda: {\n",
    "        \"person\": defaultdict(lambda: [None, None, None, None]), # Default bounding box for persons\n",
    "        \"car\": defaultdict(lambda: [None, None, None, None])    # Default bounding box for cars\n",
    "    })\n",
    "    current_frame = None\n",
    "\n",
    "    for line in json_data.split(\"\\n\"):\n",
    "        if line.startswith(\"INFO of\"):\n",
    "            current_frame = line.split(\":\")[0].split()[-1]\n",
    "\n",
    "        elif \"Person\" in line and \"bbox\" in line:\n",
    "            person_id, bbox_str = re.match(r\"Person (\\d+) .* bbox is(\\[.*?\\])\", line).groups()\n",
    "            bbox_str = bbox_str.strip('[]')\n",
    "            bbox = [float(value) for value in bbox_str.split()]\n",
    "            if is_small_bbox(bbox):\n",
    "                bbox =[ None, None, None, None]\n",
    "\n",
    "            frames[current_frame]['person'][int(person_id)] = (bbox)\n",
    "\n",
    "\n",
    "        elif \"Person\" in line and \"detected\" in line:\n",
    "            person_id = re.match(r\"Person (\\d+) is not\", line).group(1)\n",
    "\n",
    "            frames[current_frame]['person'][int(person_id)] = [None,None,None,None]\n",
    "        elif \"<V> car\" in line and \"<VE>\" in line:\n",
    "            car_id, bbox_str = re.match(r\"<V> car (\\d+) is at (\\[.*?\\]) <VE>\", line).groups()\n",
    "            bbox = [float(value) for value in bbox_str.strip('[]').split()]\n",
    "            \n",
    "            if is_small_bbox(bbox):\n",
    "                bbox =[ None, None, None, None]\n",
    "            frames[current_frame]['car'][int(car_id)] = bbox\n",
    "\n",
    "\n",
    "    return frames\n",
    "\n",
    "# Reading the raw json_data file\n",
    "file_path = \"raw_data/Info_Video_0194.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    raw_data_content = file.read()\n",
    "# Parsing the raw json_data to extract the required information\n",
    "parsed_data = parse_raw_data(raw_data_content)\n",
    "parsed_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def fill_missing_frames(json_file_path):\n",
    "    json_file_path = \"JSON_data/\" + json_file_path\n",
    "    with open(json_file_path, 'r') as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    # Find the maximum frame number\n",
    "    max_frame = int(max(json_data.keys(), key=lambda x: int(x)))\n",
    "\n",
    "    # Create an empty frame structure\n",
    "    empty_frame = {\n",
    "        \"person\": {},\n",
    "        \"car\": {}\n",
    "    }\n",
    "\n",
    "    # Fill in the missing frames with the empty frame structure\n",
    "    for frame_number in range(max_frame + 1):\n",
    "        frame_key = str(frame_number).zfill(4)\n",
    "        if frame_key not in json_data:\n",
    "            json_data[frame_key] = empty_frame\n",
    "\n",
    "    # Write the filled json_data back to the JSON file\n",
    "    with open(json_file_path, 'w') as file:\n",
    "        json.dump(json_data, file, indent=4)\n",
    "\n",
    "# Example usage\n",
    "fill_missing_frames('Bbox_Video_274e.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to JSON_data\\Bbox_Video_0194.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "def save_to_json(parsed_data, filename):\n",
    "    # Create a directory named \"JSON_data\" if it doesn't exist\n",
    "    os.makedirs('JSON_data', exist_ok=True)\n",
    "\n",
    "    # Define the path\n",
    "    path = os.path.join('JSON_data', filename)\n",
    "\n",
    "    # Convert the dictionary to a JSON string and write it to the file\n",
    "    with open(path, 'w') as file:\n",
    "        json.dump(parsed_data, file, indent=4)\n",
    "\n",
    "    print(f\"json_data has been saved to {path}\")\n",
    "\n",
    "\n",
    "\n",
    "# Usage example\n",
    "parsed_data = parse_raw_data(raw_data_content)\n",
    "filename = 'Bbox_Video_0194.json'\n",
    "save_to_json(parsed_data, filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### raw_data -> bbox\n",
    "now I have a folder of the files, named 'raw_data/Info_Video_xxxx.txt'. I want you to write a script to go over all these txt file, and :\n",
    "- data = read into str\n",
    "- parsed_data = parse_raw_data(data)\n",
    "- save_to_json(parsed_data,filename)\n",
    "For example:\n",
    "# Reading the raw data file\n",
    "file_path = \"raw_data/Info_Video_0194.txt\"\n",
    "\n",
    "with open(file_path, 'r') as file:\n",
    "    raw_data_content = file.read()\n",
    "# Parsing the raw data to extract the required information\n",
    "parsed_data = parse_raw_data(raw_data_content)\n",
    "filename = 'Bbox_Video_0194.json'\n",
    "save_to_json(parsed_data, filename)\n",
    "\n",
    "give me a script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to JSON_data\\Bbox_Video_0194.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_0382.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_03b8.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_0bb4.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_1629.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_274e.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_4659.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_4f31.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_87bd.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to JSON_data\\Bbox_Video_8e3e.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_9212.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_bd99.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_c061.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_eb61.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_fda7.json\n",
      "Data has been saved to JSON_data\\Bbox_Video_fe0a.json\n",
      "Processing completed!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Directory containing the raw data files\n",
    "raw_data_dir = \"raw_data\"\n",
    "\n",
    "# Iterate through each file in the raw data directory\n",
    "for filename in os.listdir(raw_data_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "        # Construct the full path of the file\n",
    "        file_path = os.path.join(raw_data_dir, filename)\n",
    "\n",
    "        # Read the raw data from the file\n",
    "        with open(file_path, 'r') as file:\n",
    "            raw_data_content = file.read()\n",
    "\n",
    "        # Parse the raw data\n",
    "        parsed_data = parse_raw_data(raw_data_content)\n",
    "\n",
    "        # Generate the output JSON filename\n",
    "        json_filename = 'Bbox' + filename.replace(\"Info\", \"\").replace(\".txt\", \".json\")\n",
    "\n",
    "        # Save the parsed data to a JSON file\n",
    "        save_to_json(parsed_data, json_filename)\n",
    "        \n",
    "        fill_missing_frames(json_filename)\n",
    "\n",
    "\n",
    "print(\"Processing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed text saved to: prep_data\\Prep_Info_Video_0194.md\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "def preprocess_text(text):\n",
    "    # Replace bold markdown with unique markers\n",
    "    text = text.replace('**', '||') # Using '||' as a unique marker for bold text\n",
    "    \n",
    "    # Adding distinct delimiters for each person's information\n",
    "    lines = text.split('\\n')\n",
    "    processed_lines = []\n",
    "    for line in lines:\n",
    "        if 'Person' in line and ':' in line:\n",
    "            processed_lines.append('<PERSON_INFO>') # Start of person's information\n",
    "        processed_lines.append(line)\n",
    "        if line.strip().endswith(')'):\n",
    "            processed_lines.append('</PERSON_INFO>') # End of person's information\n",
    "            \n",
    "    processed_text = '\\n'.join(processed_lines)\n",
    "    return processed_text\n",
    "\n",
    "\n",
    "def store_preprocessed_text(filename, preprocessed_text, folder='prep_data'):\n",
    "    # Create the folder if it doesn't exist\n",
    "    if not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "    \n",
    "    # Construct the new filename based on the provided name\n",
    "    base_name = os.path.basename(filename)\n",
    "    new_name = f\"Prep_{base_name.replace('.txt', '.md')}\"\n",
    "    file_path = os.path.join(folder, new_name)\n",
    "\n",
    "    # Write the preprocessed text to the new file\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(preprocessed_text)\n",
    "    \n",
    "    print(f\"Preprocessed text saved to: {file_path}\")\n",
    "\n",
    "# Example usage\n",
    "filename = \"Info_Video_0194.txt\"\n",
    "preprocessed_text = preprocess_text(result_data)\n",
    "store_preprocessed_text(filename, preprocessed_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Frame0001': {'Time': '0.5s',\n",
       "  'Text': 'The situation in Frame 0001 indicates potential risks due to the presence of persons on the road and sidewalk, their close proximity to the dashcam, and their angles near the extremes of the field of view. Additionally, the presence of persons not on any detected surface raises concerns about their unexpected positions or movements. Immediate attention and caution are advised to prevent potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('Medium', [None, None, None, None]),\n",
       "   '4': ('Medium', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0002': {'Time': '1.0s',\n",
       "  'Text': 'The situation in Frame 0002 is more critical compared to the previous frame, as more persons are now detected on the road. The high-risk evaluation for Persons 0 through 4 is due to their positions on the road or sidewalk, very close proximity to the dashcam, and angles near the extremes of the field of view. Person 5, who is not on any detected surface, is considered a medium risk. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0003': {'Time': '1.5s',\n",
       "  'Text': 'The situation in Frame 0003 remains critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0, 1, and 2 is due to their positions on the road and their very close distance to the dashcam. Immediate and cautious action is required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0004': {'Time': '2.0s',\n",
       "  'Text': 'The situation in Frame 0004 is similar to the previous frame, with persons 0, 1, and 2 still on the road or sidewalk, posing a high risk of collision. Persons 3, 4, and 5, who are not on any detected surface, are considered medium risks due to their unexpected positions. Immediate attention and caution are advised to avoid potential accidents.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('Medium', [None, None, None, None]),\n",
       "   '4': ('Medium', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0005': {'Time': '2.5s',\n",
       "  'Text': 'The situation in Frame 0005 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0006': {'Time': '3.0s',\n",
       "  'Text': 'The situation in Frame 0006 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0, 1, and 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0007': {'Time': '3.5s',\n",
       "  'Text': 'The situation in Frame 0007 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and their very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0008': {'Time': '4.0s',\n",
       "  'Text': 'The situation in Frame 0008 is similar to the previous frame, with multiple persons detected on the road and sidewalk. The high-risk evaluation for Persons 0 through 4 is due to their positions on the road or sidewalk, very close proximity to the dashcam, and angles near the extremes of the field of view. Person 5, who is on the road but not on any detected surface, is considered a medium risk. Caution should be exercised to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0009': {'Time': '4.5s',\n",
       "  'Text': 'The situation in Frame 0009 is critical, as multiple persons are detected on the road and sidewalks. The high-risk evaluation for Persons 0, 1, 2, 3, 4, 5, 8, 9, 10, and 11 is due to their positions on the road or sidewalks, close proximity to the dashcam, and negative angles indicating potential collision paths. Persons 6 and 7 are considered medium risk as they are on the sidewalk but still very close to the dashcam. Immediate attention and caution are required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('Medium', [None, None, None, None]),\n",
       "   '7': ('Medium', [None, None, None, None]),\n",
       "   '8': ('High', [None, None, None, None]),\n",
       "   '9': ('High', [None, None, None, None]),\n",
       "   '10': ('High', [None, None, None, None]),\n",
       "   '11': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0010': {'Time': '5.0s',\n",
       "  'Text': 'The situation in Frame 0010 is critical, as multiple persons are detected on the road and sidewalk. The high-risk evaluation for Persons 0, 1, 2, 4, and 5 is due to their positions on the road or sidewalk, very close proximity to the dashcam, and angles near the extremes of the field of view. Person 3, who is not on any detected surface, is considered a medium risk. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('Medium', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0011': {'Time': '5.5s',\n",
       "  'Text': 'The situation in Frame 0011 is critical, as multiple persons are detected on the road and sidewalks. The high-risk evaluation for Persons 0 through 4 and 6 is due to their positions on the road or sidewalks, very close proximity to the dashcam, and angles near the extremes of the field of view. Person 5, who is not on any detected surface, is considered a medium risk. Immediate and cautious action may be required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None])}},\n",
       " 'Frame0012': {'Time': '6.0s',\n",
       "  'Text': 'The situation in Frame 0012 is critical, as multiple persons are detected on the road and sidewalks. The high-risk evaluation for Persons 0 through 4 is due to their positions on the road or sidewalks, very close proximity to the dashcam, and angles near the extremes of the field of view. Persons 5, 6, and 7, who are not on any detected surface, are considered medium risks. Immediate attention and caution are necessary to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None]),\n",
       "   '6': ('Medium', [None, None, None, None]),\n",
       "   '7': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0013': {'Time': '6.5s',\n",
       "  'Text': 'The situation in Frame 0013 is critical, as multiple persons are detected on the road and sidewalks. Persons 0, 1, 2, and 3 pose a high risk due to their positions on the road or sidewalks, close proximity to the dashcam, and angles near the extremes of the field of view. Persons 4 and 5, who are not on any detected surface, are considered medium risks. Immediate attention and caution are necessary to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('Medium', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0014': {'Time': '7.0s',\n",
       "  'Text': 'The situation in Frame 0014 is critical, as all detected persons are either on the road or sidewalk and are very close to the dashcam. The risk evaluation for Persons 0 through 4 is high due to their positions, proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None])}},\n",
       " 'Frame0015': {'Time': '7.5s',\n",
       "  'Text': 'The situation in Frame 0015 is critical, as multiple persons are detected on the road and sidewalks. The high-risk evaluation for Persons 0 through 8 is due to their positions on the road or sidewalks, very close proximity to the dashcam, and angles near the extremes of the field of view. Person 5, who is not on any detected surface, is considered a medium risk. Immediate and cautious action may be required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None]),\n",
       "   '7': ('High', [None, None, None, None]),\n",
       "   '8': ('High', [None, None, None, None])}},\n",
       " 'Frame0016': {'Time': '8.0s',\n",
       "  'Text': 'The situation in Frame 0016 is critical, as all detected persons are on the road or sidewalks, very close to the dashcam, and at extreme angles. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None]),\n",
       "   '7': ('High', [None, None, None, None])}},\n",
       " 'Frame0017': {'Time': '8.5s',\n",
       "  'Text': 'The situation in Frame 0017 is critical, as all detected persons are either on the road or sidewalks, very close to the dashcam, and have angles near the extremes of the field of view. Person 5, who is not on any detected surface, is considered a medium risk. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0018': {'Time': '9.0s',\n",
       "  'Text': 'The situation in Frame 0018 is critical, as all detected persons are on the road or sidewalk and are very close to the dashcam. The high-risk evaluation for all persons is due to their positions on the road or sidewalk, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None])}},\n",
       " 'Frame0019': {'Time': '9.5s',\n",
       "  'Text': 'The situation in Frame 0019 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0020': {'Time': '10.0s',\n",
       "  'Text': 'The situation in Frame 0020 is critical, as all three detected persons are on the road or sidewalks, very close to the dashcam, and at extreme angles. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0021': {'Time': '10.5s',\n",
       "  'Text': 'The situation in Frame 0021 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and their very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0022': {'Time': '11.0s',\n",
       "  'Text': 'The situation in Frame 0022 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0023': {'Time': '11.5s',\n",
       "  'Text': 'The situation in Frame 0023 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0024': {'Time': '12.0s',\n",
       "  'Text': 'The situation in Frame 0024 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and their very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0025': {'Time': '12.5s',\n",
       "  'Text': 'The situation in Frame 0025 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and their very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0026': {'Time': '13.0s',\n",
       "  'Text': 'The situation in Frame 0026 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0027': {'Time': '13.5s',\n",
       "  'Text': 'The situation in Frame 0027 is critical, as all detected persons are on the road and very close to the dashcam. The high-risk evaluation for all persons is due to their positions on the road, close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None])}},\n",
       " 'Frame0028': {'Time': '14.0s',\n",
       "  'Text': 'The situation in Frame 0028 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 3 is due to their positions on both road 0 and road 1, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None])}},\n",
       " 'Frame0029': {'Time': '14.5s',\n",
       "  'Text': 'The situation in Frame 0029 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0030': {'Time': '15.0s',\n",
       "  'Text': 'The situation in Frame 0030 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for all persons is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0031': {'Time': '15.5s',\n",
       "  'Text': 'The situation in Frame 0031 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0032': {'Time': '16.0s',\n",
       "  'Text': 'The situation in Frame 0032 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0033': {'Time': '16.5s',\n",
       "  'Text': 'The situation in Frame 0033 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for all persons is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0034': {'Time': '17.0s',\n",
       "  'Text': 'The situation in Frame 0034 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0035': {'Time': '17.5s',\n",
       "  'Text': 'The situation in Frame 0035 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for all persons is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0036': {'Time': '18.0s',\n",
       "  'Text': 'The situation in Frame 0036 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for all persons is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0037': {'Time': '18.5s',\n",
       "  'Text': 'The situation in Frame 0037 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0038': {'Time': '19.0s',\n",
       "  'Text': 'The situation in Frame 0038 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road and very close proximity to the dashcam. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0039': {'Time': '19.5s',\n",
       "  'Text': 'The situation in Frame 0039 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0040': {'Time': '20.0s',\n",
       "  'Text': 'The situation in Frame 0040 is critical, as all three detected persons are on the road and in close proximity to the dashcam. Person 0, with a negative angle, is considered a high risk, along with Persons 1 and 2, who have angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0041': {'Time': '20.5s',\n",
       "  'Text': 'The situation in Frame 0041 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0042': {'Time': '21.0s',\n",
       "  'Text': 'The situation in Frame 0042 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0043': {'Time': '21.5s',\n",
       "  'Text': 'The situation in Frame 0043 is critical, as all detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 8 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None]),\n",
       "   '7': ('High', [None, None, None, None]),\n",
       "   '8': ('High', [None, None, None, None])}},\n",
       " 'Frame0044': {'Time': '22.0s',\n",
       "  'Text': 'The situation in Frame 0044 is critical, as all detected persons are on the road and very close to the dashcam. The high-risk evaluation for all persons is due to their positions on the road, close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None]),\n",
       "   '7': ('High', [None, None, None, None]),\n",
       "   '8': ('High', [None, None, None, None])}},\n",
       " 'Frame0045': {'Time': '22.5s',\n",
       "  'Text': 'The situation in Frame 0045 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0046': {'Time': '23.0s',\n",
       "  'Text': 'The situation in Frame 0046 is critical, as all three detected persons are on the road and very close to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0047': {'Time': '23.5s',\n",
       "  'Text': 'The situation in Frame 0047 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0 through 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0048': {'Time': '24.0s',\n",
       "  'Text': 'The situation in Frame 0048 is critical, as all three detected persons are on the road and in close proximity to the dashcam. The high-risk evaluation for Persons 0, 1, and 2 is due to their positions on the road, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid a potential collision.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None])}},\n",
       " 'Frame0049': {'Time': '24.5s',\n",
       "  'Text': 'The situation in Frame 0049 is critical, as all detected persons are on the road or sidewalk, very close to the dashcam, and at extreme angles. Persons 0, 1, 2, 3, 4, 5, 6, 7, and 8 are considered high risk, while Person 9 is considered medium risk. Immediate attention and caution are required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None]),\n",
       "   '7': ('High', [None, None, None, None]),\n",
       "   '8': ('High', [None, None, None, None]),\n",
       "   '9': ('Medium', [None, None, None, None])}},\n",
       " 'Frame0050': {'Time': '25.0s',\n",
       "  'Text': 'The situation in Frame 0050 is critical, as all detected persons are on the road or sidewalk and very close to the dashcam. The risk evaluation for all persons is high due to their positions, proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0051': {'Time': '25.5s',\n",
       "  'Text': 'The situation in Frame 0051 is critical, as multiple persons are detected on the road and sidewalk. The high-risk evaluation for Persons 0 through 5 is due to their positions on the road or sidewalk, very close proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action may be required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0052': {'Time': '26.0s',\n",
       "  'Text': 'The situation in Frame 0052 is critical, as all detected persons are either on the road or sidewalk, very close to the dashcam, and have angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None])}},\n",
       " 'Frame0053': {'Time': '26.5s',\n",
       "  'Text': 'The situation in Frame 0053 is critical, as all detected persons are on the road or sidewalk and are very close to the dashcam. The risk evaluation for all persons is high due to their positions, proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is required to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None])}},\n",
       " 'Frame0054': {'Time': '27.0s',\n",
       "  'Text': 'The situation in Frame 0054 is critical, as all detected persons are on the road or sidewalks and are very close to the dashcam. The risk evaluation for all persons is high due to their positions, proximity to the dashcam, and angles near the extremes of the field of view. Immediate and cautious action is necessary to avoid potential collisions.',\n",
       "  'Pedestrian': {'0': ('High', [None, None, None, None]),\n",
       "   '1': ('High', [None, None, None, None]),\n",
       "   '2': ('High', [None, None, None, None]),\n",
       "   '3': ('High', [None, None, None, None]),\n",
       "   '4': ('High', [None, None, None, None]),\n",
       "   '5': ('High', [None, None, None, None]),\n",
       "   '6': ('High', [None, None, None, None])}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "def parse_text(text, bbox_data):\n",
    "    # Initialize the result\n",
    "    result = {}\n",
    "\n",
    "    # Splitting the text into sections based on headers\n",
    "    sections = text.split('###')\n",
    "\n",
    "    # Iterate through the sections\n",
    "    for section in sections:\n",
    "        if \"Risk Evaluation\" in section:\n",
    "            # Extracting frame number\n",
    "            frame_number_match = re.search(r\"Frame (\\d+)\", section)\n",
    "\n",
    "            \n",
    "            if frame_number_match:\n",
    "                \n",
    "                # Extracting the last paragraph as text summary\n",
    "                text_summary = section.strip().split(\"\\n\\n\")[-1]\n",
    "                \n",
    "                frame_number = frame_number_match.group(1)\n",
    "                result[f\"Frame{frame_number.zfill(4)}\"] = {\n",
    "                    \"Time\": f\"{float(frame_number) /2}s\",\n",
    "                    \"Text\": text_summary,  # place holder here\n",
    "                    \"Pedestrian\": {}\n",
    "                }\n",
    "           \n",
    "                # Extracting risk evaluations for persons\n",
    "                person_info_blocks = section.split('<PERSON_INFO>')[1:]\n",
    "                for person_info_block in person_info_blocks:\n",
    "\n",
    "                    person_info = person_info_block.split('</PERSON_INFO>')[0]\n",
    "                    # person_match = re.search(r\"Person (\\d+): ([A-Za-z]+)\", person_info)\n",
    "                    person_match = re.search(r\"\\|\\|Person (\\d+):\\|\\| ([A-Za-z]+)\", person_info)\n",
    "\n",
    "                    if person_match:\n",
    "                        person, risk_level = person_match.groups()\n",
    "                        risk_level = risk_level.strip()\n",
    "                        # print(\"risk_level\",risk_level)\n",
    "                        # Getting the bounding box data\n",
    "                        bbox = bbox_data[frame_number.zfill(4)]['person'][str(person)]\n",
    "                        \n",
    "                        # Storing the extracted information\n",
    "                        result[f\"Frame{frame_number.zfill(4)}\"][\"Pedestrian\"][person] = (risk_level, bbox)\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "\n",
    "# Preprocessing the text\n",
    "preprocessed_text = preprocess_text(result_data)\n",
    "\n",
    "# Parsing the text into JSON\n",
    "json_data = parse_text(preprocessed_text, parsed_data)\n",
    "\n",
    "\n",
    "json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High\n",
      "[None, None, None, None]\n"
     ]
    }
   ],
   "source": [
    "risk,bbox = json_data[\"Frame0005\"]['Pedestrian']['0']\n",
    "print(risk)\n",
    "print(bbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data has been saved to JSON_data\\risk_evaluation_0194.json\n"
     ]
    }
   ],
   "source": [
    "save_to_json(json_data,\"risk_evaluation_0194.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_box_data(json_filename):\n",
    "    with open(json_filename, 'r') as file:\n",
    "        box_data = json.load(file)\n",
    "    return box_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Already handled JSON_data\\risk_evaluation_0001.json\n",
      "Already handled JSON_data\\risk_evaluation_0003.json\n",
      "Already handled JSON_data\\risk_evaluation_0055.json\n",
      "Already handled JSON_data\\risk_evaluation_0056.json\n",
      "Already handled JSON_data\\risk_evaluation_0057.json\n",
      "Already handled JSON_data\\risk_evaluation_0194.json\n",
      "Already handled JSON_data\\risk_evaluation_0310.json\n",
      "Already handled JSON_data\\risk_evaluation_0313.json\n",
      "Already handled JSON_data\\risk_evaluation_0333.json\n",
      "Preprocessed text saved to: prep_data\\Prep_Result_Video_0343.md\n",
      "JSON_data/Bbox_Video_0343.json\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'0'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32md:\\#Courses Folder\\##大三\\SU23\\Summer_Research_2023\\Blind_LLM_Guide_Project\\Chatbot\\vision_data_processing.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m         \u001b[39m# Load the corresponding box_data from the JSON file\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m         box_data \u001b[39m=\u001b[39m load_box_data(bbox_json)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m         json_data \u001b[39m=\u001b[39m parse_text(preprocessed_text, box_data) \u001b[39m# need to read form box json\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         save_to_json(json_data, json_filename)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=33'>34</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mProcessing completed!\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;32md:\\#Courses Folder\\##大三\\SU23\\Summer_Research_2023\\Blind_LLM_Guide_Project\\Chatbot\\vision_data_processing.ipynb Cell 22\u001b[0m in \u001b[0;36mparse_text\u001b[1;34m(text, bbox_data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m risk_level \u001b[39m=\u001b[39m risk_level\u001b[39m.\u001b[39mstrip()\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# print(\"risk_level\",risk_level)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# Getting the bounding box data\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m bbox \u001b[39m=\u001b[39m bbox_data[frame_number\u001b[39m.\u001b[39;49mzfill(\u001b[39m4\u001b[39;49m)][\u001b[39m'\u001b[39;49m\u001b[39mperson\u001b[39;49m\u001b[39m'\u001b[39;49m][\u001b[39mstr\u001b[39;49m(person)]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# Storing the extracted information\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/%23Courses%20Folder/%23%23%E5%A4%A7%E4%B8%89/SU23/Summer_Research_2023/Blind_LLM_Guide_Project/Chatbot/vision_data_processing.ipynb#X30sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m result[\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFrame\u001b[39m\u001b[39m{\u001b[39;00mframe_number\u001b[39m.\u001b[39mzfill(\u001b[39m4\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m][\u001b[39m\"\u001b[39m\u001b[39mPedestrian\u001b[39m\u001b[39m\"\u001b[39m][person] \u001b[39m=\u001b[39m (risk_level, bbox)\n",
      "\u001b[1;31mKeyError\u001b[0m: '0'"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "result_data_dir = \"LLM_data\"\n",
    "\n",
    "for filename in os.listdir(result_data_dir):\n",
    "    if filename.endswith(\".txt\"):\n",
    "\n",
    "        file_path = os.path.join(result_data_dir, filename)\n",
    "\n",
    "        json_filename = 'risk_evaluation' + filename.replace(\"Result_Video\", \"\").replace(\".txt\", \".json\")\n",
    "\n",
    "        output_path = Path('JSON_data/'+json_filename)\n",
    "        if output_path.exists():\n",
    "            print(f\"Already handled {output_path}\")\n",
    "            continue\n",
    "\n",
    "        with open(file_path, 'r') as file:\n",
    "            result_data = file.read()\n",
    "            file.close()\n",
    "\n",
    "        pre_file_path = 'prep_data/' + filename\n",
    "        preprocessed_text = preprocess_text(result_data)\n",
    "        store_preprocessed_text(pre_file_path, preprocessed_text)\n",
    "\n",
    "        bbox_json = 'JSON_data/Bbox_Video' + filename.replace(\"Result_Video\", \"\").replace(\".txt\", \".json\")\n",
    "        print(bbox_json)\n",
    "        # Load the corresponding box_data from the JSON file\n",
    "        box_data = load_box_data(bbox_json)\n",
    "        \n",
    "        json_data = parse_text(preprocessed_text, box_data) # need to read form box json\n",
    "\n",
    "        save_to_json(json_data, json_filename)\n",
    "\n",
    "print(\"Processing completed!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I wrote a code to parse the information from the raw_data, but there are two bug within it:\n",
    "1. program don't show person bbox because the raw data don't have it, I want you to record as [None, None, None, None]\n",
    "2. the key of bbox is string, I want it to be int, because it may be more convinent to search\n",
    "\n",
    "Debug now\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "非常好，那么让我们处理另外一个问题\n",
    "我现在需要将另外一个名为：all_video_name.json转化为自然语言，但是我只需要其中每个帧的行人数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_mot_conf(lines):\n",
    "    \"\"\"\n",
    "    Read the MOT file and return a dictionary mapping frame and id to confidence.\n",
    "    :param mot_file: Path to the MOT formatted file.\n",
    "    :return: Nested dictionary with frame and id as keys and confidence as value.\n",
    "    \"\"\"\n",
    "    conf_data = {}\n",
    "    for line in lines:\n",
    "        parts = line.strip().split(',')\n",
    "        frame, obj_id, _, _, _, _, conf, _, _, _ = map(float, parts)\n",
    "        frame = int(frame)\n",
    "        obj_id = int(obj_id)\n",
    "        if frame not in conf_data:\n",
    "            conf_data[frame] = {}\n",
    "        conf_data[frame][obj_id] = conf\n",
    "\n",
    "    return conf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "def transform_all_json_to_txt(video_name):\n",
    "    # Load the JSON file\n",
    "    json_filename = f'./JSON_data/all_json/all_{video_name}.json'\n",
    "    with open(json_filename, 'r') as f:\n",
    "        json_data = json.load(f)\n",
    "    mot_filename = f'./raw_data/p_mot_list/{video_name}.txt'\n",
    "    with open(mot_filename, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    conf_data = read_mot_conf(lines)\n",
    "\n",
    "    output = []\n",
    "\n",
    "    # Convert to natural language description\n",
    "    for frame, frame_data in json_data.items():\n",
    "        people = frame_data.get(\"person\", {})\n",
    "        output.append(f\"### frame {frame}\")\n",
    "\n",
    "        person_ids = list(people.keys())\n",
    "        if not person_ids:\n",
    "            output.append(\"no detected person\\n\")\n",
    "            continue\n",
    "        person_ids_str = [int(pid) for pid in people.keys()]  # Convert keys (person IDs) to integers\n",
    "        output.append(f\"people detected: {person_ids_str}\")\n",
    "\n",
    "        # For each person, display bbox\n",
    "        for pid, bbox in people.items():\n",
    "            rounded_bbox = [round(coord, 1) for coord in bbox]\n",
    "            output.append(f\"{pid} is at {rounded_bbox} \")\n",
    "\n",
    "        # Dummy logic for left/right of car based on bbox x-axis value (assuming bbox format is [x1, y1, x2, y2])\n",
    "        right_of_car = [int(pid) for pid, bbox in people.items() if bbox[0] > 960]  # using 960 as video shape threshold\n",
    "        left_of_car = [int(pid) for pid in person_ids if pid not in right_of_car]\n",
    "        output.append(f\"On right of our car, there are: {right_of_car}\")\n",
    "        output.append(f\"On the left of our car, there are {left_of_car}\")\n",
    "\n",
    "        # Logic for high/low confidence using real confidence data\n",
    "        high_confidence = [pid for pid in person_ids if float(conf_data[int(frame)][int(pid)]) >= 0.7]\n",
    "        low_confidence = [pid for pid in person_ids if float(conf_data[int(frame)][int(pid)]) <= 0.3]\n",
    "       \n",
    "\n",
    "\n",
    "        output.append(f\"high confidence: {', '.join(high_confidence) if high_confidence else 'none'}\")\n",
    "        output.append(f\"low confidence: {', '.join(low_confidence) if low_confidence else 'none'} \")\n",
    "        output.append(\"\")  # For an empty line between frames\n",
    "\n",
    "    # Save to an output file\n",
    "    with open(f'./LLM_data/0829_J2T/{video_name}.txt', 'w') as f:\n",
    "        f.write(\"\\n\".join(output))\n",
    "transform_all_json_to_txt('video_0194')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unproceessed_list = ['b4542860-0b880bb4','cd09a73f-5f6b9212','cd26264b-22001629']\n",
    "\n",
    "for name in unproceessed_list:\n",
    "    transform_all_json_to_txt(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
