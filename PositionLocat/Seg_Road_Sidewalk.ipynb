{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantic Segment Road and Sidewalk\n",
    "Tony Wang July 04 2023\n",
    "\n",
    "This notebook is used for tutuorial demo, because I believe, compared to the unstable .py file, jupyter notebook would provide a vivid description and data pipeline demonstration.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library & Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "# filter some annoying debug info\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import supervision as sv\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "import termcolor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from groundingdino.util.inference import Model\n",
    "from segment_anything import sam_model_registry, SamPredictor\n",
    "#TODO name!\n",
    "from groundingdino.util.inference import load_model, load_image, predict, annotate\n",
    "\n",
    "# import SAM_utility # \n",
    "\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# Paths to GroundingDINO and SAM checkpoints\n",
    "GROUNDING_DINO_CONFIG_PATH = \"/root/autodl-tmp/DINO/groundingdino/config/GroundingDINO_SwinT_OGC.py\"\n",
    "GROUNDING_DINO_CHECKPOINT_PATH = \"/root/autodl-tmp/DINO/weights/groundingdino_swint_ogc.pth\"\n",
    "MODEL_TYPE = \"default\"\n",
    "SAM_CHECKPOINT_PATH = \"/root/autodl-tmp/sam_vit_h_4b8939.pth\"\n",
    "\n",
    "# Predict classes and hyper-param for GroundingDINO\n",
    "BOX_TRESHOLD = 0.25\n",
    "TEXT_TRESHOLD = 0.25\n",
    "NMS_THRESHOLD = 0.8"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model loading is quite long\n",
    "with some unremovable warning in gDINO, just ignore it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "# Initialize GroundingDINO model\n",
    "grounding_dino_model = Model(\n",
    "    model_config_path=GROUNDING_DINO_CONFIG_PATH, \n",
    "    model_checkpoint_path=GROUNDING_DINO_CHECKPOINT_PATH, \n",
    "    device=DEVICE\n",
    ")\n",
    "\n",
    "# Initialize SAM model and predictor\n",
    "sam = sam_model_registry[MODEL_TYPE](checkpoint=SAM_CHECKPOINT_PATH)\n",
    "sam.to(device=DEVICE)\n",
    "sam_predictor = SamPredictor(sam)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_mask(mask, ax, random_color=False):\n",
    "    if random_color:\n",
    "        color = np.concatenate([np.random.random(3), np.array([0.6])], axis=0)\n",
    "    else:\n",
    "        color = np.array([30/255, 144/255, 255/255, 0.6])\n",
    "    h, w = mask.shape[-2:]\n",
    "    mask_image = mask.reshape(h, w, 1) * color.reshape(1, 1, -1)\n",
    "    ax.imshow(mask_image)\n",
    "    \n",
    "def show_points(coords, labels, ax, marker_size=375):\n",
    "    pos_points = coords[labels==1]\n",
    "    neg_points = coords[labels==0]\n",
    "    ax.scatter(pos_points[:, 0], pos_points[:, 1], color='green', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)\n",
    "    ax.scatter(neg_points[:, 0], neg_points[:, 1], color='red', marker='*', s=marker_size, edgecolor='white', linewidth=1.25)   \n",
    "    \n",
    "def show_box(box, ax):\n",
    "    x0, y0 = box[0], box[1]\n",
    "    w, h = box[2] - box[0], box[3] - box[1]\n",
    "    ax.add_patch(plt.Rectangle((x0, y0), w, h, edgecolor='green', facecolor=(0,0,0,0), lw=2))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_image_file(filename):\n",
    "    IMAGE_EXT = ['.jpg', '.jpeg', '.png', '.bmp']\n",
    "    return any(filename.endswith(extension) for extension in IMAGE_EXT)\n",
    "\n",
    "def display_mask(SAM_masks, image_path,output_dir,DINO_boxes):\n",
    "    # Create a new subplot\n",
    "    output_path = os.path.join(output_dir, image_path)\n",
    "    plt.figure(figsize=(16,9))\n",
    "    image = cv2.cvtColor( cv2.imread(image_path),cv2.COLOR_BGR2RGB )\n",
    "    # Display the original image\n",
    "    plt.imshow(image)\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    for mask in SAM_masks:\n",
    "        show_mask(mask, plt.gca(), random_color=True)\n",
    "    for box in DINO_boxes:\n",
    "        show_box(box, plt.gca())\n",
    "\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Architecture:\n",
    "1. gDINO : grounding_dino_model.predict_with_classes\n",
    "\n",
    "   CLASSES_prompt= ['road', 'sidewalk']\n",
    "\n",
    "   Based on testing, this pair is most reliable (otherwise the sidewalk may messed up with road) \n",
    "\n",
    "   In this part, I use the box as Region of Interest(ROI) to further prompt SAM\n",
    "\n",
    "2. Non-maximum suppression (NMS) :\n",
    "\n",
    "   get rid of redundant and overlapping bounding boxes.\n",
    "\n",
    "   the metric is Intersection over Union(IoU)\n",
    "\n",
    "3. Prompting SAM with ROI, select mask with largest area, in this step, the road and sidewalk can be segmented with naming in pixel level accuracy.\n",
    "\n",
    "4. save the result \n",
    "\n",
    "5. TODO: label the result with label and confidence\n",
    "\n",
    "6. TODO: do image sequence experiment, analyze the behavior of person\n",
    "\n",
    "7. TODO: split cases based on JAAD info\n",
    "\n",
    "   - car is moving \n",
    "   - car is stopping\n",
    "   - time\n",
    "   - weather\n",
    "   - more...\n",
    "\n",
    "In GTX3090 environment, the algorithm runs relatively fast with GPU boosting.\n",
    "\n",
    "(Not as bad as I guessed before, much faster than all of the online demo)\n",
    "\n",
    "1. dino find road √ （Regieon of interest)\n",
    "\n",
    "2. use road's bbox as prompt to use SAM\n",
    "\n",
    "   text: person, sidewalk, road, vehicle\n",
    "\n",
    "3. rule base \n",
    "\n",
    "   - comparing pixel relationship betweeen person and road, sidewalk\n",
    "   - other VQA method to generate text\n",
    "\n",
    "4. analyze image sequence, predict behavior\n",
    "\n",
    "   - question: can I try LLM to do this?\n",
    "     - 一些想法，之后会议解释\n",
    "\n",
    "5. overall must use video & image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prompting SAM with ROI\n",
    "def segment_ROI(sam_predictor: SamPredictor, image: np.ndarray, xyxy: np.ndarray):\n",
    "    sam_predictor.set_image(image)\n",
    "    result_masks = []\n",
    "    for box in xyxy:\n",
    "        masks_np, scores_np, _ = sam_predictor.predict(\n",
    "        point_coords=None,\n",
    "        point_labels=None,\n",
    "        box= box,\n",
    "        multimask_output=True,\n",
    "        )\n",
    "        index = np.argmax(scores_np)\n",
    "        result_masks.append(masks_np[index])\n",
    "\n",
    "    return np.array(result_masks)\n",
    "\n",
    "def detect_road(image_path,output_path):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            print(f\"Image at path {image_path} could not be loaded. Skipping.\")\n",
    "            return None\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "\n",
    "        image_source, image2 = load_image(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to process image at {image_path}. Error: {e}\")\n",
    "        return None\n",
    "    \n",
    "    TEXT_PROMPT = \"road . sidewalk\"\n",
    "    CLASSES = ['road', 'sidewalk']\n",
    "    \n",
    "\n",
    "    # detect objects\n",
    "    detections = grounding_dino_model.predict_with_classes(\n",
    "        image=image,\n",
    "        classes = CLASSES,\n",
    "        box_threshold= BOX_TRESHOLD,\n",
    "        text_threshold=TEXT_TRESHOLD\n",
    "    )\n",
    "\n",
    "    box_annotator = sv.BoxAnnotator()\n",
    "\n",
    "    labels = [\n",
    "    f\"{CLASSES[class_id]} {confidence:0.2f}\" \n",
    "    for _, _, confidence, class_id, _ \n",
    "    in detections]\n",
    "\n",
    "    # NMS post process\n",
    "    nms_idx = torchvision.ops.nms(\n",
    "        torch.from_numpy(detections.xyxy), \n",
    "        torch.from_numpy(detections.confidence), \n",
    "        NMS_THRESHOLD\n",
    "    ).numpy().tolist()\n",
    "\n",
    "    detections.xyxy = detections.xyxy[nms_idx]\n",
    "    detections.confidence = detections.confidence[nms_idx]\n",
    "    detections.class_id = detections.class_id[nms_idx]\n",
    "\n",
    "    DINO_boxes = np.array(detections.xyxy)\n",
    "\n",
    "    annotated_frame = box_annotator.annotate(scene=image.copy(), detections=detections, labels=labels)\n",
    "    # sv.plot_image(annotated_frame, (16, 16))\n",
    "\n",
    "\n",
    "    # cv2.imwrite(\"annotated_image.jpg\", annotated_frame)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    SAM_masks = segment_ROI(\n",
    "        sam_predictor=sam_predictor,\n",
    "        image= image,\n",
    "        xyxy= DINO_boxes,\n",
    "    )\n",
    "\n",
    "    plt.figure(figsize=(16,9))\n",
    "\n",
    "    # Display the original image\n",
    "    # plt.imshow(image)\n",
    "    plt.imshow(annotated_frame)  # Change this line\n",
    "    plt.axis('off')\n",
    "\n",
    "\n",
    "    for mask in SAM_masks:\n",
    "        show_mask(mask, plt.gca(), random_color=True)\n",
    "    for box in DINO_boxes:\n",
    "        show_box(box, plt.gca())\n",
    "\n",
    "    plt.savefig(output_path)\n",
    "    plt.close()\n",
    "\n",
    "\n",
    "\n",
    "    return DINO_boxes,labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[893.4925]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_masks = []\n",
    "mask = [  1.7368164 ,187.55162,   893.4925 ,   430.34235  ]\n",
    "score = np.array( [  1.7368164 ,187.55162,   893.4925 ,   430.34235  ])\n",
    "index = np.argmax(score)\n",
    "result_masks.append(mask[index])\n",
    "result_masks\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== Start =====\n",
      "Processing:  1\n",
      "Image path: image_0008.png\n",
      "Image at path input/video_0018/image_0008.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  2\n",
      "Image path: image_0001.png\n",
      "Image at path input/video_0020/image_0001.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  3\n",
      "Image path: image_0002.png\n",
      "Image at path input/video_0020/image_0002.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  4\n",
      "Image path: image_0003.png\n",
      "Image at path input/video_0020/image_0003.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  5\n",
      "Image path: image_0004.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at path input/video_0020/image_0004.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  6\n",
      "Image path: image_0005.png\n",
      "Image at path input/video_0020/image_0005.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  7\n",
      "Image path: image_0006.png\n",
      "Image at path input/video_0020/image_0006.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  8\n",
      "Image path: image_0007.png\n",
      "Image at path input/video_0020/image_0007.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  9\n",
      "Image path: image_0008.png\n",
      "Image at path input/video_0020/image_0008.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  10\n",
      "Image path: image_0009.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at path input/video_0020/image_0009.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  11\n",
      "Image path: image_0010.png\n",
      "Image at path input/video_0020/image_0010.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  12\n",
      "Image path: image_0011.png\n",
      "Image at path input/video_0020/image_0011.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  13\n",
      "Image path: image_0012.png\n",
      "Image at path input/video_0020/image_0012.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  14\n",
      "Image path: image_0013.png\n",
      "Image at path input/video_0020/image_0013.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  15\n",
      "Image path: image_0014.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at path input/video_0020/image_0014.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  16\n",
      "Image path: image_0015.png\n",
      "Image at path input/video_0020/image_0015.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  17\n",
      "Image path: image_0016.png\n",
      "Image at path input/video_0020/image_0016.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  18\n",
      "Image path: image_0017.png\n",
      "Image at path input/video_0020/image_0017.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  19\n",
      "Image path: image_0018.png\n",
      "Image at path input/video_0020/image_0018.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  20\n",
      "Image path: image_0001.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at path input/video_0021/image_0001.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  21\n",
      "Image path: image_0002.png\n",
      "Image at path input/video_0021/image_0002.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  22\n",
      "Image path: image_0003.png\n",
      "Image at path input/video_0021/image_0003.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  23\n",
      "Image path: image_0004.png\n",
      "Image at path input/video_0021/image_0004.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  24\n",
      "Image path: image_0005.png\n",
      "Image at path input/video_0021/image_0005.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  25\n",
      "Image path: image_0006.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n",
      "libpng error: Read Error\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image at path input/video_0021/image_0006.png could not be loaded. Skipping.\n",
      " failed to detect result\n",
      "Processing:  26\n",
      "Image path: image_0001.png\n",
      "Detected: (array([[   4.040344 ,  681.7572   , 1916.9829   , 1070.0835   ],\n",
      "       [   2.4958496,  695.2447   , 1824.8105   ,  881.4327   ]],\n",
      "      dtype=float32), ['road 0.56', 'sidewalk 0.34'])\n",
      "Processing:  27\n",
      "Image path: image_0002.png\n",
      "Detected: (array([[   4.387146 ,  687.65015  , 1916.2673   , 1070.9369   ],\n",
      "       [   3.0578613,  688.7768   , 1917.5137   ,  990.799    ],\n",
      "       [   4.111847 ,  797.8878   , 1012.699    ,  896.75195  ],\n",
      "       [   5.4229736,  711.2475   , 1633.386    ,  897.3488   ]],\n",
      "      dtype=float32), ['road 0.40', 'sidewalk 0.30', 'road 0.32', 'sidewalk 0.25'])\n",
      "Processing:  28\n",
      "Image path: image_0003.png\n",
      "Detected: (array([[4.0161133e+00, 6.9651025e+02, 1.9165444e+03, 1.0736506e+03],\n",
      "       [5.7609863e+00, 6.9726196e+02, 1.9161823e+03, 9.7091809e+02],\n",
      "       [1.2233887e+00, 8.0690332e+02, 8.3867938e+02, 9.0724951e+02],\n",
      "       [1.6180420e+00, 7.3722180e+02, 1.1946050e+03, 9.0686731e+02],\n",
      "       [1.9502563e+00, 7.1947546e+02, 1.4973403e+03, 9.0845398e+02]],\n",
      "      dtype=float32), ['road 0.45', 'sidewalk 0.29', 'sidewalk 0.31', 'sidewalk 0.26', 'road 0.32'])\n",
      "Processing:  29\n",
      "Image path: image_0004.png\n",
      "Detected: (array([[1.3569480e+03, 7.0062585e+02, 1.9186943e+03, 9.4707910e+02],\n",
      "       [1.9034424e+00, 7.2666040e+02, 1.1843630e+03, 9.0151575e+02],\n",
      "       [4.4378052e+00, 7.0541162e+02, 1.9159878e+03, 1.0696367e+03],\n",
      "       [1.4778098e+03, 7.0322913e+02, 1.9176582e+03, 9.4612451e+02],\n",
      "       [1.5515442e+00, 8.0466199e+02, 7.4880554e+02, 9.0157275e+02]],\n",
      "      dtype=float32), ['road 0.29', 'sidewalk 0.25', 'road 0.38', 'sidewalk 0.30', 'road 0.27'])\n",
      "Processing:  30\n",
      "Image path: image_0005.png\n",
      "Detected: (array([[1.3269099e+03, 7.0090063e+02, 1.9179551e+03, 9.4771655e+02],\n",
      "       [3.9265747e+00, 7.2594427e+02, 1.6537380e+03, 9.9333392e+02],\n",
      "       [1.3465881e+00, 8.0408533e+02, 6.9710547e+02, 9.0115869e+02]],\n",
      "      dtype=float32), ['road 0.52', 'sidewalk 0.28', 'sidewalk 0.34'])\n",
      "Processing:  31\n",
      "Image path: image_0006.png\n",
      "Detected: (array([[1.3105520e+03, 7.0262640e+02, 1.9182722e+03, 9.4802655e+02],\n",
      "       [1.3506775e+00, 8.0335443e+02, 6.8663660e+02, 9.0038837e+02],\n",
      "       [1.2478638e+00, 7.3166132e+02, 1.3761018e+03, 9.0086920e+02]],\n",
      "      dtype=float32), ['road 0.48', 'sidewalk 0.30', 'sidewalk 0.26'])\n",
      "Processing:  32\n",
      "Image path: image_0007.png\n",
      "Detected: (array([[1.3099296e+03, 7.0349292e+02, 1.9180187e+03, 9.4720544e+02],\n",
      "       [4.0187378e+00, 7.0766101e+02, 1.9159885e+03, 1.0719918e+03],\n",
      "       [1.3588867e+00, 8.0357526e+02, 6.7891687e+02, 9.0050604e+02]],\n",
      "      dtype=float32), ['road 0.43', 'sidewalk 0.26', 'road 0.32'])\n",
      "Processing:  33\n",
      "Image path: image_0008.png\n",
      "Detected: (array([[4.6251221e+00, 7.1511780e+02, 1.9158530e+03, 1.0691683e+03],\n",
      "       [6.4848633e+00, 7.1611804e+02, 1.9151882e+03, 9.8277661e+02],\n",
      "       [3.2411194e+00, 7.6247095e+02, 9.5580969e+02, 8.9144128e+02],\n",
      "       [1.2695688e+03, 7.1418762e+02, 1.9177390e+03, 9.4667419e+02],\n",
      "       [1.8951416e+00, 7.3527191e+02, 1.2767582e+03, 8.9113556e+02]],\n",
      "      dtype=float32), ['road 0.38', 'road 0.27', 'sidewalk 0.27', 'sidewalk 0.30', 'road 0.34'])\n",
      "Processing:  34\n",
      "Image path: image_0009.png\n",
      "Detected: (array([[   4.8511963,  712.1517   , 1916.2098   , 1000.0462   ],\n",
      "       [   1.9855652,  743.87964  ,  933.6376   ,  873.755    ],\n",
      "       [1206.0383   ,  714.65686  , 1918.3      ,  947.5492   ]],\n",
      "      dtype=float32), ['road 0.46', 'road 0.28', 'sidewalk 0.31'])\n",
      "Processing:  35\n",
      "Image path: image_0010.png\n",
      "Detected: (array([[   3.798584 ,  718.31573  , 1916.179    , 1001.8278   ],\n",
      "       [1191.5057   ,  715.8206   , 1918.6051   ,  946.6425   ],\n",
      "       [   2.7380981,  932.6954   , 1916.6726   , 1077.4612   ]],\n",
      "      dtype=float32), ['road 0.43', 'road 0.27', 'sidewalk 0.25', 'road 0.27'])\n"
     ]
    }
   ],
   "source": [
    "image_dir = Path(\"input\") # contain many folder \n",
    "output_dir = Path('DINOmasked')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"===== Start =====\")\n",
    "i = 1\n",
    "# Use rglob to recursively find all image files\n",
    "for image_path in image_dir.rglob('*'):\n",
    "    if is_image_file(str(image_path)):\n",
    "        relative_path = image_path.relative_to(image_dir)\n",
    "\n",
    "        output_path = output_dir / relative_path\n",
    "        output_path.parent.mkdir(parents=True,exist_ok=True)\n",
    "\n",
    "        if not output_path.exists():\n",
    "            print(\"Processing: \", i)\n",
    "            i += 1\n",
    "            print(f\"Image path: {termcolor.colored(os.path.basename(str(image_path)), 'green')}\")\n",
    "\n",
    "            result = detect_road(str(image_path),str(output_path))\n",
    "\n",
    "            if result is not None:\n",
    "                print(f\"Detected: {image_path}\") # {termcolor.colored(result, 'blue')}\")\n",
    "            else:\n",
    "                fail_str = \"failed to detect result\"\n",
    "                print(f\" {termcolor.colored(fail_str, 'red')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
